{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc41b896",
   "metadata": {},
   "source": [
    "# Rule based Chatbot-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcecf5f5-4ff1-4c1b-938f-89cd98cadcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "root = Tk()\n",
    "root.title(\"iPEC-Chatbot\")\n",
    "def send():\n",
    "    send = \"You -> \"+e.get()\n",
    "    txt.insert(END, \" \"+send)\n",
    "    user = e.get().lower()\n",
    "    if(user == \"hello\"):\n",
    "        txt.insert(END, \"\\n iPEC\" + \"Robo -> Hi  \")\n",
    "    elif(user == \"hi\" or user == \"hii\" or user == \"hiiii\"):\n",
    "        txt.insert(END, \"\\n iPEC\" + \"Robo -> Hello  \")\n",
    "    elif(e.get() == \"how are you  \"):\n",
    "        txt.insert(END, \"\\n iPEC\" + \"Robo -> fine! and you  \")\n",
    "    elif(user == \"fine\" or user == \"i am good\" or user == \"i am doing good  \"):\n",
    "        txt.insert(END, \"\\n iPEC\" + \"Robo -> Great! how can I help you.  \")\n",
    "    else:\n",
    "        txt.insert(END, \"\\n iPEC\" + \"Robo -> Sorry! I dind't got you  \")\n",
    "    e.delete(0, END)\n",
    "txt = Text(root)\n",
    "txt.grid(row=0, column=0, columnspan=2)\n",
    "e = Entry(root, width=100)\n",
    "e.grid(row=1, column=0)\n",
    "send = Button(root, text=\"Send\", command=send).grid(row=1, column=1)\n",
    "root.mainloop()\n",
    "\n",
    "# Rule based Chatbot-2 \n",
    "### Extracting TF-IDF features and reading data from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d3fd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53675eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(r\"C:\\Users\\vkram\\Downloads\\Chatbot.txt\",'r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower()# converts to lowercase\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences\n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c481abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badde57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what’s up\",\"hey\",\"yo\")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f100348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    spar_response=\"\"\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        spar_response=spar_response+\"I don’t understand you\"\n",
    "        return spar_response\n",
    "    else:\n",
    "        spar_response = spar_response+sent_tokens[idx]\n",
    "        return spar_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb30cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPEC-Bot: My name is iPEC-Bot. I will answer your queries about Chatbots. If you want to exit, type Bye! \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPEC-Bot: hi there\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miPEC-Bot:\u001b[39m\u001b[38;5;124m\"\u001b[39m ,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;28mprint\u001b[39m(response(user_response))\n\u001b[1;32m---> 16\u001b[0m         sent_tokens\u001b[38;5;241m.\u001b[39mremove(user_response)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"iPEC-Bot: My name is iPEC-Bot. I will answer your queries about Chatbots. If you want to exit, type Bye! \")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you '):\n",
    "            flag=False\n",
    "            print(\"iPEC-Bot: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"iPEC-Bot: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"iPEC-Bot:\" ,end=\" \")\n",
    "                print(response(user_response))\n",
    "            sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba5f88",
   "metadata": {},
   "source": [
    "# Using Reflections Chatbot-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b7ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd7c6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reflections = {\n",
    "  \"i am\"       : \"you are\",\n",
    "  \"i was\"      : \"you were\",\n",
    "  \"i\"          : \"you\",\n",
    "  \"i'm\"        : \"you are\",\n",
    "  \"i'd\"        : \"you would\",\n",
    "  \"i've\"       : \"you have\",\n",
    "  \"i'll\"       : \"you will\",\n",
    "  \"my\"         : \"your\",\n",
    "  \"you are\"    : \"I am\",\n",
    "  \"you were\"   : \"I was\",\n",
    "  \"you've\"     : \"I have\",\n",
    "  \"you'll\"     : \"I will\",\n",
    "  \"your\"       : \"my\",\n",
    "  \"yours\"      : \"mine\",\n",
    "  \"you\"        : \"me\",\n",
    "  \"me\"         : \"you\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5787034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    [\n",
    "        r\"my name is (.*)\",\n",
    "        [\"Hello %1, How are you today ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"hi|hey|hello\",\n",
    "        [\"Hello\", \"Hey there\",]\n",
    "    ], \n",
    "    [\n",
    "        r\"what is your name ?\",\n",
    "        [\"I am a bot created by iPEC Solutions Private Limited. you can call me crazy!\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"how are you ?\",\n",
    "        [\"I'm doing goodnHow about You ?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"sorry (.*)\",\n",
    "        [\"Its alright\",\"Its OK, never mind\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"I am fine\",\n",
    "        [\"Great to hear that, How can I help you?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"i'm (.*) doing good\",\n",
    "        [\"Nice to hear that\",\"How can I help you?:)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) age?\",\n",
    "        [\"I'm a computer program dude n Seriously you are asking me this?\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"what (.*) want ?\",\n",
    "        [\"Make me an offer I can't refuse\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) created ?\",\n",
    "        [\"Rose created me using Python's NLTK library \",\"top secret ;)\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (location|city) ?\",\n",
    "        ['Bangalore, Karnataka',]\n",
    "    ],\n",
    "    [\n",
    "        r\"how is weather in (.*)?\",\n",
    "        [\"Weather in %1 is awesome like always\",\"Too hot man here in %1\",\"Too cold man here in %1\",\"Never even heard about %1\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i work in (.*)?\",\n",
    "        [\"%1 is an Amazing company, I have heard about it. But they are in huge loss these days.\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*)raining in (.*)\",\n",
    "        [\"No rain since last week here in %2\",\"Damn its raining too much here in %2\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"how (.*) health(.*)\",\n",
    "        [\"I'm a computer program, so I'm always healthy \",]\n",
    "    ],\n",
    "    [\n",
    "        r\"(.*) (sports|game) ?\",\n",
    "        [\"I'm a very big fan of Football\",]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) sportsperson ?\",\n",
    "        [\"Messy\",\"Ronaldo\",\"Roony\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"who (.*) (moviestar|actor)?\",\n",
    "        [\"Brad Pitt\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"i am looking for online guides and courses to learn Pychology, can you suggest?\",\n",
    "        [\"iPEC_Solutions has many great articles with each step explanation along with code, you can explore\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"quit\",\n",
    "        [\"BBye take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
    "    ],\n",
    "    [\n",
    "        r\"which courses are in I Pec|which types of courses in your i pec\",\n",
    "        [\"Data sceince, Generative Artificial intelligence, Data Analyst,Python Mastery\"]\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "153286eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Hi! I am a chatbot created by iPEC Solutions Private Limited for your service\")\n",
    "    chat = Chat(pairs, reflections)\n",
    "    chat.converse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96202571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I am a chatbot created by iPEC Solutions Private Limited for your service\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "> what is data science\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "> which courses are in I Pec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sceince, Generative Artificial intelligence, Data Analyst,Python Mastery\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "> bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "> exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "> quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBye take care. See you soon :) \n"
     ]
    }
   ],
   "source": [
    "#initiate the conversation\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45557f77",
   "metadata": {},
   "source": [
    "# 4. Chatbot using Deep Learning\n",
    "tensorflow==2.3.1 </br>\n",
    "nltk==3.5</br>\n",
    "colorama==0.4.3</br>\n",
    "numpy==1.18.5</br>\n",
    "scikit_learn==0.23.2</br>\n",
    "Flask==1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e08590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0eca5b",
   "metadata": {},
   "source": [
    "#### Step 1: Data Creation and save as json file format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d792be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data and save as json file format\n",
    "J={\"intents\": [\n",
    "    {\"tag\": \"greeting\",\n",
    "     \"patterns\": [\"Hi\", \"Hey\", \"Is anyone there?\", \"Hello\", \"Hay\"],\n",
    "     \"responses\": [\"Hello\", \"Hi\", \"Hi there\"]\n",
    "    },\n",
    "    {\"tag\": \"goodbye\",\n",
    "     \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
    "     \"responses\": [\"See you later\", \"Have a nice day\", \"Bye! Come back again\"]\n",
    "    },\n",
    "    {\"tag\": \"thanks\",\n",
    "     \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thanks for the help\"],\n",
    "     \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\", \"You're most welcome!\"]\n",
    "    },\n",
    "    {\"tag\": \"about\",\n",
    "     \"patterns\": [\"Who are you?\", \"What are you?\", \"Who you are?\" ],\n",
    "     \"responses\": [\"I.m iPEC Assistant, your personal assistant\", \"I'm iPEC Assistant, an Artificial Intelligent bot\"]\n",
    "    },\n",
    "    {\"tag\": \"name\",\n",
    "    \"patterns\": [\"what is your name\", \"what should I call you\", \"whats your name?\"],\n",
    "    \"responses\": [\"You can call me Darling.\", \"I'm iPEC Assistant!\", \"Just call me as Babby\"]\n",
    "    },\n",
    "    {\"tag\": \"help\",\n",
    "    \"patterns\": [\"Could you help me?\", \"give me a hand please\", \"Can you help?\", \"What can you do for me?\", \"I need a support\", \"I need a help\", \"support me please\"],\n",
    "    \"responses\": [\"Tell me how can assist you\", \"Tell me your problem to assist you\", \"Yes Sure, How can I support you\"]\n",
    "    },\n",
    "    {\"tag\": \"createaccount\",\n",
    "    \"patterns\": [\"I need to create a new account\", \"how to open a new account\", \"I want to create an account\", \"can you create an account for me\", \"how to open a new account\"],\n",
    "    \"responses\": [\"You can just easily create a new account from our web site\", \"Just go to our web site and follow the guidelines to create a new account\"]\n",
    "    },\n",
    "    {\"tag\": \"complaint\",\n",
    "    \"patterns\": [\"have a complaint\", \"I want to raise a complaint\", \"there is a complaint about a service\"],\n",
    "    \"responses\": [\"Please provide us your complaint in order to assist you\", \"Please mention your complaint, we will reach you and sorry for any inconvenience caused\"]\n",
    "    }\n",
    "]\n",
    "}\n",
    "\n",
    "# Save the intents to a JSON file\n",
    "with open(\"intents.json\", \"w\") as f:\n",
    "    json.dump(J, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da7644",
   "metadata": {},
   "source": [
    "#### Step 2: Data preparation:\n",
    "The second step of this task to create a chatbot with Python and Machine Learning is to prepare the data to train our chatbot. Start this step by importing the necessary libraries and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49f569ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []  \n",
    "responses = []\n",
    "\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9689dc26",
   "metadata": {},
   "source": [
    "#### 3.Label Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ae0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06795682",
   "metadata": {},
   "source": [
    "#### 4.Tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "968cb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a8c570",
   "metadata": {},
   "source": [
    "#### 5. Training a Neural Network¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ee3f989-0789-4122-a849-c5d16670f7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_2           │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_2           │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 910ms/step - accuracy: 0.0625 - loss: 2.08 ━━━━━━━━━━━━━━━━━━━━ 1s 31ms/step - accuracy: 0.0612 - loss: 2.0829 \n",
      "Epoch 2/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step - accuracy: 0.1250 - loss: 2.078 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.1225 - loss: 2.0788\n",
      "Epoch 3/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 20ms/step - accuracy: 0.1875 - loss: 2.077 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.2039 - loss: 2.0768\n",
      "Epoch 4/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step - accuracy: 0.2188 - loss: 2.074 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.2143 - loss: 2.0749\n",
      "Epoch 5/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.2188 - loss: 2.074 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2143 - loss: 2.0738\n",
      "Epoch 6/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.2188 - loss: 2.072 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.2143 - loss: 2.0728\n",
      "Epoch 7/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.2188 - loss: 2.071 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2143 - loss: 2.0717\n",
      "Epoch 8/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2188 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.2143 - loss: 2.0713\n",
      "Epoch 9/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.2188 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2143 - loss: 2.0710\n",
      "Epoch 10/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2188 - loss: 2.071 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.2143 - loss: 2.0711\n",
      "Epoch 11/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step - accuracy: 0.2188 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.2143 - loss: 2.0704\n",
      "Epoch 12/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2188 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2143 - loss: 2.0701\n",
      "Epoch 13/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - accuracy: 0.2500 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 32ms/step - accuracy: 0.2449 - loss: 2.0702\n",
      "Epoch 14/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2812 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2756 - loss: 2.0695\n",
      "Epoch 15/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 18ms/step - accuracy: 0.2500 - loss: 2.068 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.2449 - loss: 2.0692\n",
      "Epoch 16/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.1562 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - accuracy: 0.1733 - loss: 2.0694\n",
      "Epoch 17/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 24ms/step - accuracy: 0.1250 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.1427 - loss: 2.0688\n",
      "Epoch 18/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step - accuracy: 0.1250 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.1427 - loss: 2.0684\n",
      "Epoch 19/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 19ms/step - accuracy: 0.1562 - loss: 2.067 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step - accuracy: 0.1531 - loss: 2.0674\n",
      "Epoch 20/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.1562 - loss: 2.067 ━━━━━━━━━━━━━━━━━━━━ 0s 35ms/step - accuracy: 0.1531 - loss: 2.0671\n",
      "Epoch 21/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step - accuracy: 0.1562 - loss: 2.067 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - accuracy: 0.1531 - loss: 2.0662\n",
      "Epoch 22/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.1562 - loss: 2.064 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step - accuracy: 0.1531 - loss: 2.0647\n",
      "Epoch 23/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 21ms/step - accuracy: 0.1250 - loss: 2.065 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step - accuracy: 0.1427 - loss: 2.0643\n",
      "Epoch 24/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - accuracy: 0.1562 - loss: 2.064 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.1531 - loss: 2.0627\n",
      "Epoch 25/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.1875 - loss: 2.058 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1837 - loss: 2.0600\n",
      "Epoch 26/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3125 - loss: 2.057 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3062 - loss: 2.0589\n",
      "Epoch 27/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 2.056 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3674 - loss: 2.0578\n",
      "Epoch 28/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 2.054 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.2143 - loss: 2.0567\n",
      "Epoch 29/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2188 - loss: 2.054 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2143 - loss: 2.0561\n",
      "Epoch 30/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.2188 - loss: 2.053 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2143 - loss: 2.0553\n",
      "Epoch 31/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.1875 - loss: 2.058 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.2039 - loss: 2.0570\n",
      "Epoch 32/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.1875 - loss: 2.05 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2039 - loss: 2.0566 \n",
      "Epoch 33/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2188 - loss: 2.052 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2143 - loss: 2.0541\n",
      "Epoch 34/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2188 - loss: 2.055 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2143 - loss: 2.0547\n",
      "Epoch 35/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1875 - loss: 2.056 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.2039 - loss: 2.0547\n",
      "Epoch 36/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1875 - loss: 2.056 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.2039 - loss: 2.0539\n",
      "Epoch 37/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1875 - loss: 2.055 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.2039 - loss: 2.0529\n",
      "Epoch 38/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2188 - loss: 2.046 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.2143 - loss: 2.0494\n",
      "Epoch 39/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.2188 - loss: 2.047 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.2143 - loss: 2.0489\n",
      "Epoch 40/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1875 - loss: 2.053 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2039 - loss: 2.0503\n",
      "Epoch 41/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2188 - loss: 2.044 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2143 - loss: 2.0469\n",
      "Epoch 42/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1875 - loss: 2.052 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.2039 - loss: 2.0493\n",
      "Epoch 43/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.2188 - loss: 2.043 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.2143 - loss: 2.0458\n",
      "Epoch 44/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1875 - loss: 2.051 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2039 - loss: 2.0477\n",
      "Epoch 45/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 2.040 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.2143 - loss: 2.0437\n",
      "Epoch 46/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.2188 - loss: 2.046 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2143 - loss: 2.0450\n",
      "Epoch 47/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2188 - loss: 2.037 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2143 - loss: 2.0416\n",
      "Epoch 48/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2188 - loss: 2.038 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.2143 - loss: 2.0410\n",
      "Epoch 49/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 2.043 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2143 - loss: 2.0422\n",
      "Epoch 50/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.2188 - loss: 2.042 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2143 - loss: 2.0416\n",
      "Epoch 51/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.2188 - loss: 2.042 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2143 - loss: 2.0411\n",
      "Epoch 52/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.1875 - loss: 2.045 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2039 - loss: 2.0422\n",
      "Epoch 53/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2188 - loss: 2.042 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2143 - loss: 2.0408\n",
      "Epoch 54/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 2.034 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2143 - loss: 2.0375\n",
      "Epoch 55/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2188 - loss: 2.032 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2143 - loss: 2.0355\n",
      "Epoch 56/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2188 - loss: 2.038 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2143 - loss: 2.0363\n",
      "Epoch 57/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.2188 - loss: 2.030 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2143 - loss: 2.0334\n",
      "Epoch 58/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2188 - loss: 2.037 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2143 - loss: 2.0354\n",
      "Epoch 59/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.2143 - loss: 2.0324\n",
      "Epoch 60/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2188 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2143 - loss: 2.0316\n",
      "Epoch 61/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2188 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.2143 - loss: 2.0308\n",
      "Epoch 62/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.2188 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.2143 - loss: 2.0304\n",
      "Epoch 63/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1875 - loss: 2.036 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.2039 - loss: 2.0334\n",
      "Epoch 64/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.2188 - loss: 2.026 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.2143 - loss: 2.0296\n",
      "Epoch 65/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2188 - loss: 2.026 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2143 - loss: 2.0296\n",
      "Epoch 66/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2188 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2143 - loss: 2.0298\n",
      "Epoch 67/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.2188 - loss: 2.034 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.2143 - loss: 2.0326\n",
      "Epoch 68/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 222ms/step - accuracy: 0.1875 - loss: 2.03 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.2039 - loss: 2.0334 \n",
      "Epoch 69/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2188 - loss: 2.033 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.2143 - loss: 2.0319\n",
      "Epoch 70/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2188 - loss: 2.031 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.2143 - loss: 2.0304\n",
      "Epoch 71/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1875 - loss: 2.032 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.2039 - loss: 2.0294\n",
      "Epoch 72/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.2143 - loss: 2.0266\n",
      "Epoch 73/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1875 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.2039 - loss: 2.0256\n",
      "Epoch 74/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.1875 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1998 - loss: 2.025 ━━━━━━━━━━━━━━━━━━━━ 0s 165ms/step - accuracy: 0.2039 - loss: 2.0244\n",
      "Epoch 75/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2188 - loss: 2.016 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.2143 - loss: 2.0195\n",
      "Epoch 76/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2188 - loss: 2.015 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.2143 - loss: 2.0182\n",
      "Epoch 77/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2188 - loss: 2.013 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.2143 - loss: 2.0166\n",
      "Epoch 78/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2188 - loss: 2.012 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.2143 - loss: 2.0152\n",
      "Epoch 79/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.1875 - loss: 2.023 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2039 - loss: 2.0180\n",
      "Epoch 80/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2188 - loss: 2.016 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.2143 - loss: 2.0149\n",
      "Epoch 81/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1875 - loss: 2.021 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2039 - loss: 2.0156\n",
      "Epoch 82/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2188 - loss: 2.015 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.2143 - loss: 2.0129\n",
      "Epoch 83/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1875 - loss: 2.018 ━━━━━━━━━━━━━━━━━━━━ 0s 99ms/step - accuracy: 0.2039 - loss: 2.0129\n",
      "Epoch 84/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2188 - loss: 2.004 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2143 - loss: 2.0073\n",
      "Epoch 85/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.2188 - loss: 2.002 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.2143 - loss: 2.0058\n",
      "Epoch 86/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.2188 - loss: 2.002 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.2143 - loss: 2.0049\n",
      "Epoch 87/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 207ms/step - accuracy: 0.2188 - loss: 2.00 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.2143 - loss: 2.0047 \n",
      "Epoch 88/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2188 - loss: 2.003 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2143 - loss: 2.0048\n",
      "Epoch 89/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2188 - loss: 1.998 ━━━━━━━━━━━━━━━━━━━━ 0s 105ms/step - accuracy: 0.2143 - loss: 2.0039\n",
      "Epoch 90/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1875 - loss: 2.018 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2039 - loss: 2.0114\n",
      "Epoch 91/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 2.000 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2143 - loss: 2.0055\n",
      "Epoch 92/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 2.009 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2143 - loss: 2.0083\n",
      "Epoch 93/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2188 - loss: 2.005 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.2143 - loss: 2.0061\n",
      "Epoch 94/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.2188 - loss: 2.007 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2143 - loss: 2.0052\n",
      "Epoch 95/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 2.002 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2143 - loss: 2.0033\n",
      "Epoch 96/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2188 - loss: 2.007 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.2143 - loss: 2.0039\n",
      "Epoch 97/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2188 - loss: 1.992 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.2143 - loss: 1.9983\n",
      "Epoch 98/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1875 - loss: 2.011 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2039 - loss: 2.0046\n",
      "Epoch 99/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1875 - loss: 2.011 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.2039 - loss: 2.0040\n",
      "Epoch 100/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2188 - loss: 2.006 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2143 - loss: 2.0013\n",
      "Epoch 101/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2188 - loss: 1.997 ━━━━━━━━━━━━━━━━━━━━ 0s 109ms/step - accuracy: 0.2143 - loss: 1.9973\n",
      "Epoch 102/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 1.986 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.2143 - loss: 1.9928\n",
      "Epoch 103/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2188 - loss: 1.983 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.2143 - loss: 1.9904\n",
      "Epoch 104/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2188 - loss: 1.999 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.2143 - loss: 1.9943\n",
      "Epoch 105/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.1875 - loss: 2.000 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2039 - loss: 1.9929\n",
      "Epoch 106/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 1.976 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.2143 - loss: 1.9830\n",
      "Epoch 107/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 1.990 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.2143 - loss: 1.9855\n",
      "Epoch 108/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1875 - loss: 1.993 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2039 - loss: 1.9848\n",
      "Epoch 109/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1875 - loss: 1.991 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2039 - loss: 1.9827\n",
      "Epoch 110/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2188 - loss: 1.983 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2143 - loss: 1.9793\n",
      "Epoch 111/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2188 - loss: 1.965 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2143 - loss: 1.9725\n",
      "Epoch 112/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2188 - loss: 1.967 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.2143 - loss: 1.9719\n",
      "Epoch 113/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2188 - loss: 1.973 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2143 - loss: 1.9727\n",
      "Epoch 114/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.2188 - loss: 1.971 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.2143 - loss: 1.9708\n",
      "Epoch 115/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.2188 - loss: 1.969 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.2143 - loss: 1.9689\n",
      "Epoch 116/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.1875 - loss: 1.980 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2039 - loss: 1.9716\n",
      "Epoch 117/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2188 - loss: 1.975 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2143 - loss: 1.9689\n",
      "Epoch 118/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2812 - loss: 1.954 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.2756 - loss: 1.9612\n",
      "Epoch 119/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2812 - loss: 1.976 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2958 - loss: 1.9674\n",
      "Epoch 120/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3125 - loss: 1.953 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.3062 - loss: 1.9582\n",
      "Epoch 121/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.2812 - loss: 1.951 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.2756 - loss: 1.9561\n",
      "Epoch 122/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2812 - loss: 1.949 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2756 - loss: 1.9539\n",
      "Epoch 123/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 1.957 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2143 - loss: 1.9557\n",
      "Epoch 124/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1875 - loss: 1.967 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.2039 - loss: 1.9580\n",
      "Epoch 125/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2188 - loss: 1.944 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2143 - loss: 1.9496\n",
      "Epoch 126/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.2188 - loss: 1.942 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.2143 - loss: 1.9483\n",
      "Epoch 127/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.2188 - loss: 1.937 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.2143 - loss: 1.9463\n",
      "Epoch 128/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 1.954 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2143 - loss: 1.9520\n",
      "Epoch 129/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2188 - loss: 1.943 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.2143 - loss: 1.9469\n",
      "Epoch 130/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.2188 - loss: 1.941 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.2143 - loss: 1.9448\n",
      "Epoch 131/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2188 - loss: 1.950 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.2143 - loss: 1.9466\n",
      "Epoch 132/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2812 - loss: 1.934 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.2756 - loss: 1.9394\n",
      "Epoch 133/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3125 - loss: 1.944 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.3062 - loss: 1.9398\n",
      "Epoch 134/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3438 - loss: 1.929 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.3368 - loss: 1.9333\n",
      "Epoch 135/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3125 - loss: 1.944 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3229 - loss: 1.939 ━━━━━━━━━━━━━━━━━━━━ 0s 146ms/step - accuracy: 0.3264 - loss: 1.9373\n",
      "Epoch 136/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3750 - loss: 1.926 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3674 - loss: 1.9310\n",
      "Epoch 137/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.917 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3674 - loss: 1.9267\n",
      "Epoch 138/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3750 - loss: 1.929 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3674 - loss: 1.9293\n",
      "Epoch 139/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3750 - loss: 1.921 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.3674 - loss: 1.9248\n",
      "Epoch 140/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3750 - loss: 1.924 ━━━━━━━━━━━━━━━━━━━━ 0s 105ms/step - accuracy: 0.3674 - loss: 1.9242\n",
      "Epoch 141/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3438 - loss: 1.931 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3570 - loss: 1.9251\n",
      "Epoch 142/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3750 - loss: 1.915 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.3674 - loss: 1.9184\n",
      "Epoch 143/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3438 - loss: 1.929 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3570 - loss: 1.9222\n",
      "Epoch 144/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 1.919 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3368 - loss: 1.9183\n",
      "Epoch 145/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3438 - loss: 1.913 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.3368 - loss: 1.9155\n",
      "Epoch 146/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3438 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3368 - loss: 1.9182\n",
      "Epoch 147/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3438 - loss: 1.910 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3368 - loss: 1.9125\n",
      "Epoch 148/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3125 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3229 - loss: 1.916 ━━━━━━━━━━━━━━━━━━━━ 0s 133ms/step - accuracy: 0.3264 - loss: 1.9145\n",
      "Epoch 149/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.903 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.9068\n",
      "Epoch 150/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3438 - loss: 1.917 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3570 - loss: 1.9096\n",
      "Epoch 151/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3438 - loss: 1.914 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3570 - loss: 1.9062\n",
      "Epoch 152/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.893 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.8970\n",
      "Epoch 153/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3750 - loss: 1.897 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3674 - loss: 1.8962\n",
      "Epoch 154/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3750 - loss: 1.876 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.3674 - loss: 1.8875\n",
      "Epoch 155/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3438 - loss: 1.903 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.3570 - loss: 1.8946\n",
      "Epoch 156/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3750 - loss: 1.877 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3674 - loss: 1.8847\n",
      "Epoch 157/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3438 - loss: 1.899 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3570 - loss: 1.8900\n",
      "Epoch 158/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3438 - loss: 1.896 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3570 - loss: 1.8877\n",
      "Epoch 159/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 117ms/step - accuracy: 0.3750 - loss: 1.86 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3674 - loss: 1.8753 \n",
      "Epoch 160/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3438 - loss: 1.874 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3368 - loss: 1.8785\n",
      "Epoch 161/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3438 - loss: 1.874 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.3368 - loss: 1.8774\n",
      "Epoch 162/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3438 - loss: 1.871 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.3368 - loss: 1.8757\n",
      "Epoch 163/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3125 - loss: 1.890 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.3264 - loss: 1.8821\n",
      "Epoch 164/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3125 - loss: 1.889 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3264 - loss: 1.8801\n",
      "Epoch 165/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3438 - loss: 1.866 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3368 - loss: 1.8695\n",
      "Epoch 166/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3438 - loss: 1.865 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3368 - loss: 1.8661\n",
      "Epoch 167/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3438 - loss: 1.872 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3368 - loss: 1.8658\n",
      "Epoch 168/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3438 - loss: 1.870 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.8618\n",
      "Epoch 169/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3438 - loss: 1.873 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3570 - loss: 1.8624\n",
      "Epoch 170/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3750 - loss: 1.857 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3674 - loss: 1.8612\n",
      "Epoch 171/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3750 - loss: 1.859 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3674 - loss: 1.8653\n",
      "Epoch 172/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3438 - loss: 1.880 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3570 - loss: 1.8724\n",
      "Epoch 173/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3438 - loss: 1.887 ━━━━━━━━━━━━━━━━━━━━ 0s 112ms/step - accuracy: 0.3570 - loss: 1.8723\n",
      "Epoch 174/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.840 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3674 - loss: 1.8542\n",
      "Epoch 175/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3750 - loss: 1.842 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.8511\n",
      "Epoch 176/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3750 - loss: 1.834 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3674 - loss: 1.8429\n",
      "Epoch 177/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.833 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.8365\n",
      "Epoch 178/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3750 - loss: 1.823 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3693 - loss: 1.826 ━━━━━━━━━━━━━━━━━━━━ 0s 143ms/step - accuracy: 0.3674 - loss: 1.8271\n",
      "Epoch 179/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.818 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3674 - loss: 1.8212\n",
      "Epoch 180/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3750 - loss: 1.818 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.8205\n",
      "Epoch 181/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3750 - loss: 1.806 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3674 - loss: 1.8211\n",
      "Epoch 182/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.847 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.3570 - loss: 1.8404\n",
      "Epoch 183/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3438 - loss: 1.852 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3570 - loss: 1.8448\n",
      "Epoch 184/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3750 - loss: 1.821 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3674 - loss: 1.8302\n",
      "Epoch 185/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3438 - loss: 1.842 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.8288\n",
      "Epoch 186/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3750 - loss: 1.808 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3674 - loss: 1.8101\n",
      "Epoch 187/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.800 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.3674 - loss: 1.8029\n",
      "Epoch 188/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3438 - loss: 1.809 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.8039\n",
      "Epoch 189/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3750 - loss: 1.788 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3674 - loss: 1.7956\n",
      "Epoch 190/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.805 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3570 - loss: 1.7992\n",
      "Epoch 191/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3750 - loss: 1.787 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3674 - loss: 1.7909\n",
      "Epoch 192/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3750 - loss: 1.769 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3674 - loss: 1.7821\n",
      "Epoch 193/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 1.809 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.7927\n",
      "Epoch 194/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.790 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3570 - loss: 1.7841\n",
      "Epoch 195/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3750 - loss: 1.771 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3693 - loss: 1.774 ━━━━━━━━━━━━━━━━━━━━ 0s 145ms/step - accuracy: 0.3674 - loss: 1.7749\n",
      "Epoch 196/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 1.794 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3570 - loss: 1.7798\n",
      "Epoch 197/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.791 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3570 - loss: 1.7753\n",
      "Epoch 198/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.753 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3693 - loss: 1.759 ━━━━━━━━━━━━━━━━━━━━ 0s 149ms/step - accuracy: 0.3674 - loss: 1.7615\n",
      "Epoch 199/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3438 - loss: 1.791 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3570 - loss: 1.7724\n",
      "Epoch 200/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.789 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3570 - loss: 1.7702\n",
      "Epoch 201/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.789 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.7689\n",
      "Epoch 202/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3750 - loss: 1.752 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.7568\n",
      "Epoch 203/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3750 - loss: 1.749 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3674 - loss: 1.7537\n",
      "Epoch 204/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.742 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.7462\n",
      "Epoch 205/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.732 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.7367\n",
      "Epoch 206/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3438 - loss: 1.740 ━━━━━━━━━━━━━━━━━━━━ 0s 114ms/step - accuracy: 0.3570 - loss: 1.7341\n",
      "Epoch 207/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3750 - loss: 1.719 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.7222\n",
      "Epoch 208/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3438 - loss: 1.729 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3570 - loss: 1.7230\n",
      "Epoch 209/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.714 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3674 - loss: 1.7165\n",
      "Epoch 210/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.702 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3674 - loss: 1.7118\n",
      "Epoch 211/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3750 - loss: 1.712 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3674 - loss: 1.7155\n",
      "Epoch 212/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3438 - loss: 1.730 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3570 - loss: 1.7232\n",
      "Epoch 213/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3750 - loss: 1.692 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3674 - loss: 1.7115\n",
      "Epoch 214/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3438 - loss: 1.729 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3570 - loss: 1.7217\n",
      "Epoch 215/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3438 - loss: 1.724 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.3570 - loss: 1.7163\n",
      "Epoch 216/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.720 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3570 - loss: 1.7106\n",
      "Epoch 217/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.686 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3674 - loss: 1.6959\n",
      "Epoch 218/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3438 - loss: 1.719 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3570 - loss: 1.7043\n",
      "Epoch 219/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3750 - loss: 1.667 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3693 - loss: 1.680 ━━━━━━━━━━━━━━━━━━━━ 0s 120ms/step - accuracy: 0.3674 - loss: 1.6846\n",
      "Epoch 220/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.674 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3674 - loss: 1.6838\n",
      "Epoch 221/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3750 - loss: 1.678 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.6830\n",
      "Epoch 222/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3438 - loss: 1.696 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3570 - loss: 1.6864\n",
      "Epoch 223/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.693 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3570 - loss: 1.6827\n",
      "Epoch 224/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3750 - loss: 1.669 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3674 - loss: 1.6731\n",
      "Epoch 225/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.660 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.6686\n",
      "Epoch 226/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3438 - loss: 1.698 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3570 - loss: 1.6802\n",
      "Epoch 227/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3750 - loss: 1.660 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.6657\n",
      "Epoch 228/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3750 - loss: 1.639 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3674 - loss: 1.6559\n",
      "Epoch 229/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3750 - loss: 1.635 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3674 - loss: 1.6518\n",
      "Epoch 230/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3438 - loss: 1.688 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3570 - loss: 1.6673\n",
      "Epoch 231/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3750 - loss: 1.641 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3674 - loss: 1.6486\n",
      "Epoch 232/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.639 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3674 - loss: 1.6440\n",
      "Epoch 233/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3750 - loss: 1.631 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3674 - loss: 1.6379\n",
      "Epoch 234/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3438 - loss: 1.649 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3570 - loss: 1.6413\n",
      "Epoch 235/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.626 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.3674 - loss: 1.6315\n",
      "Epoch 236/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3438 - loss: 1.669 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3570 - loss: 1.6443\n",
      "Epoch 237/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3750 - loss: 1.623 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3693 - loss: 1.626 ━━━━━━━━━━━━━━━━━━━━ 0s 135ms/step - accuracy: 0.3674 - loss: 1.6275\n",
      "Epoch 238/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3750 - loss: 1.621 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.6259\n",
      "Epoch 239/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.614 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3674 - loss: 1.6207\n",
      "Epoch 240/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.3438 - loss: 1.626 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3570 - loss: 1.6206\n",
      "Epoch 241/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3438 - loss: 1.623 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3570 - loss: 1.6172\n",
      "Epoch 242/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3438 - loss: 1.620 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3570 - loss: 1.6144\n",
      "Epoch 243/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3438 - loss: 1.621 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.6129\n",
      "Epoch 244/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 117ms/step - accuracy: 0.3750 - loss: 1.60 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.3674 - loss: 1.6052 \n",
      "Epoch 245/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3438 - loss: 1.635 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.6146\n",
      "Epoch 246/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3438 - loss: 1.633 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.3570 - loss: 1.6117\n",
      "Epoch 247/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3750 - loss: 1.593 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3674 - loss: 1.5989\n",
      "Epoch 248/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.584 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3674 - loss: 1.5977\n",
      "Epoch 249/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3750 - loss: 1.600 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3674 - loss: 1.6025\n",
      "Epoch 250/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.570 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3674 - loss: 1.5889\n",
      "Epoch 251/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.564 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3693 - loss: 1.577 ━━━━━━━━━━━━━━━━━━━━ 0s 162ms/step - accuracy: 0.3674 - loss: 1.5819\n",
      "Epoch 252/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3750 - loss: 1.576 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.3674 - loss: 1.5802\n",
      "Epoch 253/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3750 - loss: 1.552 ━━━━━━━━━━━━━━━━━━━━ 0s 106ms/step - accuracy: 0.3674 - loss: 1.5681\n",
      "Epoch 254/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3750 - loss: 1.555 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3674 - loss: 1.5679\n",
      "Epoch 255/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3750 - loss: 1.574 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.3674 - loss: 1.5757\n",
      "Epoch 256/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4688 - loss: 1.577 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.4593 - loss: 1.5809\n",
      "Epoch 257/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.4688 - loss: 1.623 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.4795 - loss: 1.5996\n",
      "Epoch 258/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.4688 - loss: 1.594 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.4795 - loss: 1.5887\n",
      "Epoch 259/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.5000 - loss: 1.561 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.4924 - loss: 1.569 ━━━━━━━━━━━━━━━━━━━━ 0s 141ms/step - accuracy: 0.4899 - loss: 1.5719\n",
      "Epoch 260/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.4688 - loss: 1.575 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.4795 - loss: 1.5712\n",
      "Epoch 261/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.4375 - loss: 1.594 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.4460 - loss: 1.577 ━━━━━━━━━━━━━━━━━━━━ 0s 146ms/step - accuracy: 0.4489 - loss: 1.5713\n",
      "Epoch 262/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.3438 - loss: 1.589 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.3570 - loss: 1.5633\n",
      "Epoch 263/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.543 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.5468\n",
      "Epoch 264/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.547 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.3674 - loss: 1.5512\n",
      "Epoch 265/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.598 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3570 - loss: 1.5709\n",
      "Epoch 266/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.3750 - loss: 1.537 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3674 - loss: 1.5523\n",
      "Epoch 267/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3750 - loss: 1.552 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3674 - loss: 1.5542\n",
      "Epoch 268/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3750 - loss: 1.521 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3674 - loss: 1.5367\n",
      "Epoch 269/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.525 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3674 - loss: 1.5299\n",
      "Epoch 270/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.3438 - loss: 1.531 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3570 - loss: 1.5257\n",
      "Epoch 271/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3750 - loss: 1.514 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3674 - loss: 1.5174\n",
      "Epoch 272/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.556 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.3876 - loss: 1.5333\n",
      "Epoch 273/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.4688 - loss: 1.516 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.4593 - loss: 1.5205\n",
      "Epoch 274/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.4375 - loss: 1.557 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.4489 - loss: 1.5319\n",
      "Epoch 275/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.4062 - loss: 1.510 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.4182 - loss: 1.5126\n",
      "Epoch 276/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.4062 - loss: 1.516 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.4182 - loss: 1.5115\n",
      "Epoch 277/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.4375 - loss: 1.486 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.4287 - loss: 1.4995\n",
      "Epoch 278/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.4062 - loss: 1.483 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3980 - loss: 1.4958\n",
      "Epoch 279/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.4375 - loss: 1.494 ━━━━━━━━━━━━━━━━━━━━ 0s 112ms/step - accuracy: 0.4287 - loss: 1.4972\n",
      "Epoch 280/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.4375 - loss: 1.468 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4287 - loss: 1.4859\n",
      "Epoch 281/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3750 - loss: 1.500 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3876 - loss: 1.4952\n",
      "Epoch 282/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3438 - loss: 1.532 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.3570 - loss: 1.5054\n",
      "Epoch 283/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3438 - loss: 1.534 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.5066\n",
      "Epoch 284/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3750 - loss: 1.479 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.4901\n",
      "Epoch 285/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3750 - loss: 1.477 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3674 - loss: 1.4877\n",
      "Epoch 286/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3750 - loss: 1.473 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3674 - loss: 1.4804\n",
      "Epoch 287/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3750 - loss: 1.468 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3674 - loss: 1.4724\n",
      "Epoch 288/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4062 - loss: 1.509 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4182 - loss: 1.4827\n",
      "Epoch 289/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.4688 - loss: 1.474 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.4795 - loss: 1.4700\n",
      "Epoch 290/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5000 - loss: 1.454 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.4899 - loss: 1.4623\n",
      "Epoch 291/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 227ms/step - accuracy: 0.4688 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.4795 - loss: 1.4774 \n",
      "Epoch 292/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.5000 - loss: 1.468 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.5101 - loss: 1.4632\n",
      "Epoch 293/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.5000 - loss: 1.492 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5101 - loss: 1.4678\n",
      "Epoch 294/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.4688 - loss: 1.443 ━━━━━━━━━━━━━━━━━━━━ 0s 113ms/step - accuracy: 0.4593 - loss: 1.4473\n",
      "Epoch 295/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3750 - loss: 1.453 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3876 - loss: 1.4474\n",
      "Epoch 296/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.4062 - loss: 1.420 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.3980 - loss: 1.4345\n",
      "Epoch 297/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3750 - loss: 1.431 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.3674 - loss: 1.4364\n",
      "Epoch 298/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.424 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3674 - loss: 1.4321\n",
      "Epoch 299/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 1.469 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3570 - loss: 1.4450\n",
      "Epoch 300/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3750 - loss: 1.409 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3674 - loss: 1.4225\n",
      "Epoch 301/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3750 - loss: 1.419 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3674 - loss: 1.4244\n",
      "Epoch 302/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.403 ━━━━━━━━━━━━━━━━━━━━ 0s 107ms/step - accuracy: 0.3674 - loss: 1.4166\n",
      "Epoch 303/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.432 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.4247\n",
      "Epoch 304/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3438 - loss: 1.459 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3570 - loss: 1.4330\n",
      "Epoch 305/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3438 - loss: 1.429 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.4215\n",
      "Epoch 306/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3438 - loss: 1.455 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3570 - loss: 1.4289\n",
      "Epoch 307/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.3750 - loss: 1.401 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3674 - loss: 1.4094\n",
      "Epoch 308/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3750 - loss: 1.400 ━━━━━━━━━━━━━━━━━━━━ 0s 108ms/step - accuracy: 0.3674 - loss: 1.4070\n",
      "Epoch 309/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.398 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.3674 - loss: 1.4041\n",
      "Epoch 310/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.392 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3674 - loss: 1.3982\n",
      "Epoch 311/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3438 - loss: 1.406 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3570 - loss: 1.3996\n",
      "Epoch 312/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3438 - loss: 1.432 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3570 - loss: 1.4051\n",
      "Epoch 313/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.3750 - loss: 1.369 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.3674 - loss: 1.3829\n",
      "Epoch 314/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3438 - loss: 1.400 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3570 - loss: 1.3910\n",
      "Epoch 315/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3750 - loss: 1.376 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3674 - loss: 1.3819\n",
      "Epoch 316/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3438 - loss: 1.398 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3570 - loss: 1.3883\n",
      "Epoch 317/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3750 - loss: 1.353 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.3731\n",
      "Epoch 318/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.397 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.3876 - loss: 1.3869\n",
      "Epoch 319/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.4062 - loss: 1.419 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4182 - loss: 1.3929\n",
      "Epoch 320/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.4062 - loss: 1.394 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4182 - loss: 1.3830\n",
      "Epoch 321/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.4375 - loss: 1.366 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.4287 - loss: 1.3729\n",
      "Epoch 322/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.4375 - loss: 1.352 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.4287 - loss: 1.3670\n",
      "Epoch 323/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.4375 - loss: 1.338 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4287 - loss: 1.3582\n",
      "Epoch 324/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4688 - loss: 1.350 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.4593 - loss: 1.3567\n",
      "Epoch 325/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4375 - loss: 1.394 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.4489 - loss: 1.3685\n",
      "Epoch 326/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5625 - loss: 1.340 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.5511 - loss: 1.3488\n",
      "Epoch 327/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.5312 - loss: 1.365 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.5407 - loss: 1.3534\n",
      "Epoch 328/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.5312 - loss: 1.332 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.5407 - loss: 1.3363\n",
      "Epoch 329/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.5312 - loss: 1.311 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.5205 - loss: 1.3251\n",
      "Epoch 330/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.5000 - loss: 1.334 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.5101 - loss: 1.3299\n",
      "Epoch 331/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5000 - loss: 1.335 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.5101 - loss: 1.3268\n",
      "Epoch 332/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4688 - loss: 1.299 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.4593 - loss: 1.3140\n",
      "Epoch 333/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.4062 - loss: 1.299 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3980 - loss: 1.3141\n",
      "Epoch 334/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.309 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.3674 - loss: 1.3168\n",
      "Epoch 335/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.334 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.3876 - loss: 1.3231\n",
      "Epoch 336/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.4062 - loss: 1.304 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3980 - loss: 1.3118\n",
      "Epoch 337/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3750 - loss: 1.304 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.3674 - loss: 1.3106\n",
      "Epoch 338/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3750 - loss: 1.300 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3693 - loss: 1.305 ━━━━━━━━━━━━━━━━━━━━ 0s 127ms/step - accuracy: 0.3674 - loss: 1.3067\n",
      "Epoch 339/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.4062 - loss: 1.295 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.3980 - loss: 1.3024\n",
      "Epoch 340/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.4062 - loss: 1.272 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3980 - loss: 1.2907\n",
      "Epoch 341/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.4375 - loss: 1.283 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.4287 - loss: 1.2896\n",
      "Epoch 342/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.4375 - loss: 1.324 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.4489 - loss: 1.2991\n",
      "Epoch 343/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.4688 - loss: 1.319 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.4795 - loss: 1.2947\n",
      "Epoch 344/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.5625 - loss: 1.270 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.5511 - loss: 1.2758\n",
      "Epoch 345/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.5625 - loss: 1.310 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.5713 - loss: 1.2875\n",
      "Epoch 346/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.5625 - loss: 1.310 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.5713 - loss: 1.2856\n",
      "Epoch 347/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.6875 - loss: 1.309 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6938 - loss: 1.2845\n",
      "Epoch 348/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6875 - loss: 1.277 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6938 - loss: 1.2735\n",
      "Epoch 349/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6875 - loss: 1.274 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.6938 - loss: 1.2705\n",
      "Epoch 350/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6250 - loss: 1.254 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.6124 - loss: 1.2606\n",
      "Epoch 351/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6250 - loss: 1.246 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.6326 - loss: 1.2538\n",
      "Epoch 352/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.6562 - loss: 1.236 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.6430 - loss: 1.2472\n",
      "Epoch 353/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6562 - loss: 1.232 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6430 - loss: 1.2422\n",
      "Epoch 354/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6562 - loss: 1.238 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6430 - loss: 1.2438\n",
      "Epoch 355/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6562 - loss: 1.227 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.6430 - loss: 1.2421\n",
      "Epoch 356/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6250 - loss: 1.231 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.6124 - loss: 1.2451\n",
      "Epoch 357/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5938 - loss: 1.290 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6020 - loss: 1.2655\n",
      "Epoch 358/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.7188 - loss: 1.255 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.7244 - loss: 1.2542\n",
      "Epoch 359/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.7188 - loss: 1.243 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.7244 - loss: 1.2491\n",
      "Epoch 360/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.7188 - loss: 1.282 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.7244 - loss: 1.2592\n",
      "Epoch 361/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.7188 - loss: 1.246 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.7244 - loss: 1.2422\n",
      "Epoch 362/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6250 - loss: 1.239 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6326 - loss: 1.2336\n",
      "Epoch 363/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.6250 - loss: 1.257 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.6326 - loss: 1.2336\n",
      "Epoch 364/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.5938 - loss: 1.249 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6020 - loss: 1.2258\n",
      "Epoch 365/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.5312 - loss: 1.195 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.5407 - loss: 1.2045\n",
      "Epoch 366/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.5312 - loss: 1.208 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5407 - loss: 1.2063\n",
      "Epoch 367/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.5938 - loss: 1.217 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6020 - loss: 1.2066\n",
      "Epoch 368/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6562 - loss: 1.188 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6430 - loss: 1.1952\n",
      "Epoch 369/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6250 - loss: 1.199 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6326 - loss: 1.1968\n",
      "Epoch 370/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5938 - loss: 1.207 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6020 - loss: 1.1971\n",
      "Epoch 371/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.5625 - loss: 1.208 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.5713 - loss: 1.1949\n",
      "Epoch 372/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5312 - loss: 1.192 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.5407 - loss: 1.1886\n",
      "Epoch 373/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.5000 - loss: 1.191 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.5101 - loss: 1.1875\n",
      "Epoch 374/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.5312 - loss: 1.174 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5407 - loss: 1.1799\n",
      "Epoch 375/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.5938 - loss: 1.158 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.5818 - loss: 1.1691\n",
      "Epoch 376/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6562 - loss: 1.143 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6430 - loss: 1.1583\n",
      "Epoch 377/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6562 - loss: 1.182 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.6632 - loss: 1.1729\n",
      "Epoch 378/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.6875 - loss: 1.160 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.6736 - loss: 1.1701\n",
      "Epoch 379/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6562 - loss: 1.186 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6632 - loss: 1.1756\n",
      "Epoch 380/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6875 - loss: 1.137 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.6736 - loss: 1.1514\n",
      "Epoch 381/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6562 - loss: 1.138 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.6430 - loss: 1.1460\n",
      "Epoch 382/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6250 - loss: 1.160 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6326 - loss: 1.1499\n",
      "Epoch 383/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.5625 - loss: 1.175 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.5713 - loss: 1.1539\n",
      "Epoch 384/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5625 - loss: 1.125 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.5511 - loss: 1.1394\n",
      "Epoch 385/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.5312 - loss: 1.112 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.5205 - loss: 1.1353\n",
      "Epoch 386/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5312 - loss: 1.131 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.5407 - loss: 1.1357\n",
      "Epoch 387/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5625 - loss: 1.150 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.5713 - loss: 1.1374\n",
      "Epoch 388/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6250 - loss: 1.160 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6326 - loss: 1.1409\n",
      "Epoch 389/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5625 - loss: 1.148 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.5713 - loss: 1.1359\n",
      "Epoch 390/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.5312 - loss: 1.156 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5407 - loss: 1.1351\n",
      "Epoch 391/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5625 - loss: 1.110 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.5511 - loss: 1.1177\n",
      "Epoch 392/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.5312 - loss: 1.101 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5205 - loss: 1.1152\n",
      "Epoch 393/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.5312 - loss: 1.150 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.5407 - loss: 1.1287\n",
      "Epoch 394/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.5625 - loss: 1.099 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.5511 - loss: 1.1067\n",
      "Epoch 395/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5625 - loss: 1.115 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5713 - loss: 1.1080\n",
      "Epoch 396/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6250 - loss: 1.114 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6326 - loss: 1.1041\n",
      "Epoch 397/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6250 - loss: 1.110 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6326 - loss: 1.0989\n",
      "Epoch 398/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.6562 - loss: 1.070 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6430 - loss: 1.0844\n",
      "Epoch 399/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6250 - loss: 1.080 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6124 - loss: 1.0859\n",
      "Epoch 400/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6250 - loss: 1.094 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.6326 - loss: 1.0876\n",
      "Epoch 401/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.6250 - loss: 1.074 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6124 - loss: 1.0796\n",
      "Epoch 402/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.5312 - loss: 1.094 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.5407 - loss: 1.0866\n",
      "Epoch 403/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.5625 - loss: 1.050 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.5511 - loss: 1.0746\n",
      "Epoch 404/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5312 - loss: 1.117 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.5407 - loss: 1.0963\n",
      "Epoch 405/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.5312 - loss: 1.067 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.5407 - loss: 1.0742\n",
      "Epoch 406/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.5625 - loss: 1.049 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.5511 - loss: 1.0622\n",
      "Epoch 407/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6250 - loss: 1.050 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6124 - loss: 1.0608\n",
      "Epoch 408/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.7500 - loss: 1.048 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.7348 - loss: 1.0563\n",
      "Epoch 409/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.7500 - loss: 1.047 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.7551 - loss: 1.0516\n",
      "Epoch 410/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 246ms/step - accuracy: 0.6875 - loss: 1.05 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.6938 - loss: 1.0550 \n",
      "Epoch 411/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.7188 - loss: 1.069 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.7244 - loss: 1.0733\n",
      "Epoch 412/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6875 - loss: 1.134 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6938 - loss: 1.1130\n",
      "Epoch 413/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6875 - loss: 1.105 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.6736 - loss: 1.1171\n",
      "Epoch 414/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6562 - loss: 1.131 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6632 - loss: 1.1337\n",
      "Epoch 415/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.7188 - loss: 1.111 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.7042 - loss: 1.1251\n",
      "Epoch 416/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6875 - loss: 1.116 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.6938 - loss: 1.1151\n",
      "Epoch 417/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.7188 - loss: 1.097 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.7244 - loss: 1.0928\n",
      "Epoch 418/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7188 - loss: 1.063 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.7244 - loss: 1.0662\n",
      "Epoch 419/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6875 - loss: 1.079 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6938 - loss: 1.0592\n",
      "Epoch 420/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.6875 - loss: 1.034 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6938 - loss: 1.0359\n",
      "Epoch 421/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6875 - loss: 1.024 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.6938 - loss: 1.0256\n",
      "Epoch 422/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.7188 - loss: 0.995 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7042 - loss: 1.0123\n",
      "Epoch 423/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6875 - loss: 1.032 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6938 - loss: 1.0229\n",
      "Epoch 424/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6875 - loss: 0.999 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6736 - loss: 1.0107\n",
      "Epoch 425/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6562 - loss: 1.035 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.6632 - loss: 1.0216\n",
      "Epoch 426/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6562 - loss: 1.016 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.6632 - loss: 1.0149\n",
      "Epoch 427/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6562 - loss: 1.001 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6632 - loss: 1.0082\n",
      "Epoch 428/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.6562 - loss: 1.008 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.6632 - loss: 1.0083\n",
      "Epoch 429/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.6562 - loss: 1.004 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6632 - loss: 1.0045\n",
      "Epoch 430/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6562 - loss: 1.028 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6632 - loss: 1.0091\n",
      "Epoch 431/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6875 - loss: 0.979 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.6736 - loss: 0.9902\n",
      "Epoch 432/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6562 - loss: 1.008 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.6632 - loss: 0.9984\n",
      "Epoch 433/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6875 - loss: 0.982 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6736 - loss: 0.9880\n",
      "Epoch 434/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7188 - loss: 0.963 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.7042 - loss: 0.9820\n",
      "Epoch 435/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.7188 - loss: 0.979 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.7244 - loss: 0.9896\n",
      "Epoch 436/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.8125 - loss: 0.956 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.7961 - loss: 0.9788\n",
      "Epoch 437/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.7812 - loss: 0.980 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.7857 - loss: 0.9817\n",
      "Epoch 438/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.7812 - loss: 0.991 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.7857 - loss: 0.9832\n",
      "Epoch 439/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.8125 - loss: 0.963 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.7961 - loss: 0.9797\n",
      "Epoch 440/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.7812 - loss: 0.993 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.7857 - loss: 1.0007\n",
      "Epoch 441/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.7812 - loss: 1.007 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7857 - loss: 1.0147\n",
      "Epoch 442/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.7812 - loss: 1.031 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.7857 - loss: 1.0270\n",
      "Epoch 443/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7500 - loss: 1.010 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7551 - loss: 1.0153\n",
      "Epoch 444/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.7188 - loss: 0.996 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7244 - loss: 0.9990\n",
      "Epoch 445/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6875 - loss: 0.977 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6938 - loss: 0.9802\n",
      "Epoch 446/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6875 - loss: 0.990 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6938 - loss: 0.9746\n",
      "Epoch 447/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.7188 - loss: 0.946 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7042 - loss: 0.9556\n",
      "Epoch 448/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6875 - loss: 0.969 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.6938 - loss: 0.9625\n",
      "Epoch 449/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6875 - loss: 0.977 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6938 - loss: 0.9636\n",
      "Epoch 450/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6875 - loss: 0.981 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6938 - loss: 0.9625\n",
      "Epoch 451/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6875 - loss: 0.977 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6938 - loss: 0.9588\n",
      "Epoch 452/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.7188 - loss: 0.943 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7244 - loss: 0.9447\n",
      "Epoch 453/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7188 - loss: 0.951 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.7244 - loss: 0.9445\n",
      "Epoch 454/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.7812 - loss: 0.912 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.7655 - loss: 0.9283\n",
      "Epoch 455/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.7812 - loss: 0.902 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7655 - loss: 0.9226\n",
      "Epoch 456/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.7812 - loss: 0.932 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.7857 - loss: 0.9320\n",
      "Epoch 457/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.8125 - loss: 0.933 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.8163 - loss: 0.9320\n",
      "Epoch 458/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.8438 - loss: 0.903 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.8267 - loss: 0.9226\n",
      "Epoch 459/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7500 - loss: 0.917 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.7348 - loss: 0.9282\n",
      "Epoch 460/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7188 - loss: 0.936 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.7244 - loss: 0.9337\n",
      "Epoch 461/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.7188 - loss: 0.904 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.7042 - loss: 0.9220\n",
      "Epoch 462/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.7188 - loss: 0.903 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.7042 - loss: 0.9199\n",
      "Epoch 463/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6875 - loss: 0.941 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6938 - loss: 0.9321\n",
      "Epoch 464/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6562 - loss: 0.927 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.6632 - loss: 0.9245\n",
      "Epoch 465/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6562 - loss: 0.917 ━━━━━━━━━━━━━━━━━━━━ 0s 105ms/step - accuracy: 0.6632 - loss: 0.9148\n",
      "Epoch 466/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6875 - loss: 0.912 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6938 - loss: 0.9092\n",
      "Epoch 467/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6875 - loss: 0.929 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.6938 - loss: 0.9169\n",
      "Epoch 468/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6875 - loss: 0.929 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.6938 - loss: 0.9199\n",
      "Epoch 469/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6875 - loss: 0.933 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6938 - loss: 0.9244\n",
      "Epoch 470/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6250 - loss: 0.955 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.6326 - loss: 0.9373\n",
      "Epoch 471/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step - accuracy: 0.6562 - loss: 0.89 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.6430 - loss: 0.9219 \n",
      "Epoch 472/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6250 - loss: 0.912 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.6326 - loss: 0.9211\n",
      "Epoch 473/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6875 - loss: 0.879 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.6736 - loss: 0.8922\n",
      "Epoch 474/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.7188 - loss: 0.877 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.7244 - loss: 0.8837\n",
      "Epoch 475/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.7812 - loss: 0.886 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.7857 - loss: 0.8910\n",
      "Epoch 476/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.7812 - loss: 0.906 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.7857 - loss: 0.9100\n",
      "Epoch 477/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.7188 - loss: 0.917 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.7042 - loss: 0.9279\n",
      "Epoch 478/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.6562 - loss: 0.944 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.6632 - loss: 0.9471\n",
      "Epoch 479/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6562 - loss: 0.940 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6632 - loss: 0.9415\n",
      "Epoch 480/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.6562 - loss: 0.916 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6632 - loss: 0.9181\n",
      "Epoch 481/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6875 - loss: 0.874 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6938 - loss: 0.8857\n",
      "Epoch 482/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.7812 - loss: 0.831 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.7655 - loss: 0.8564\n",
      "Epoch 483/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.7188 - loss: 0.872 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.7244 - loss: 0.8634\n",
      "Epoch 484/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6875 - loss: 0.878 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6938 - loss: 0.8627\n",
      "Epoch 485/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6875 - loss: 0.882 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6938 - loss: 0.8653\n",
      "Epoch 486/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6875 - loss: 0.869 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.6938 - loss: 0.8632\n",
      "Epoch 487/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 209ms/step - accuracy: 0.6875 - loss: 0.87 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.6938 - loss: 0.8691 \n",
      "Epoch 488/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6875 - loss: 0.904 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6938 - loss: 0.8861\n",
      "Epoch 489/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.7188 - loss: 0.855 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.7042 - loss: 0.8701\n",
      "Epoch 490/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6875 - loss: 0.860 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6922 - loss: 0.863 ━━━━━━━━━━━━━━━━━━━━ 0s 151ms/step - accuracy: 0.6938 - loss: 0.8642\n",
      "Epoch 491/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6875 - loss: 0.846 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6938 - loss: 0.8496\n",
      "Epoch 492/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.7188 - loss: 0.823 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.7230 - loss: 0.832 ━━━━━━━━━━━━━━━━━━━━ 0s 129ms/step - accuracy: 0.7244 - loss: 0.8351\n",
      "Epoch 493/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.7812 - loss: 0.859 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.7857 - loss: 0.8426\n",
      "Epoch 494/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.8125 - loss: 0.832 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.8163 - loss: 0.8338\n",
      "Epoch 495/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.8125 - loss: 0.821 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.8163 - loss: 0.8314\n",
      "Epoch 496/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.8125 - loss: 0.839 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.8163 - loss: 0.8392\n",
      "Epoch 497/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.8125 - loss: 0.837 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.8163 - loss: 0.8405\n",
      "Epoch 498/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.8125 - loss: 0.868 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.8163 - loss: 0.8520\n",
      "Epoch 499/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.8125 - loss: 0.839 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.8163 - loss: 0.8425\n",
      "Epoch 500/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.8125 - loss: 0.849 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.8163 - loss: 0.8447\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)\n",
    "\n",
    "#### 6. Saving The Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15107879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# to save the trained model\n",
    "model.save(\"chat_model.h5\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# to save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# to save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824408c5",
   "metadata": {},
   "source": [
    "#### 7.Chatbot Design with Trained Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27815937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 221ms/st ━━━━━━━━━━━━━━━━━━━━ 0s 285ms/step\n",
      "ChatBot: Hello\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is data science\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step\n",
      "ChatBot: Hi there\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " tell me Artificial intelligence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 129ms/step\n",
      "ChatBot: Tell me your problem to assist you\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " i want to know about Artificial intelligence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 33ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step\n",
      "ChatBot: Please mention your complaint, we will reach you and sorry for any inconvenience caused\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f89a09",
   "metadata": {},
   "source": [
    "# 5. Chatbot using LogisticRegression and Making it as web Application\n",
    "- Steps to Build Chat Web Application\n",
    "- Define Intents\n",
    "- Create training data\n",
    "- Train the chatbot\n",
    "- Build the chatbot\n",
    "- Test the chatbot\n",
    "- Deploy the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf0e04d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vkram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import ssl\n",
    "import streamlit as st\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.data.path.append(os.path.abspath(\"nltk_data\"))\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05944a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = [\n",
    "    {\n",
    "        \"tag\": \"greeting\",\n",
    "        \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"How are you\", \"What's up\"],\n",
    "        \"responses\": [\"Hi there\", \"Hello\", \"Hey\", \"I'm fine, thank you\", \"Nothing much\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"goodbye\",\n",
    "        \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Take care\"],\n",
    "        \"responses\": [\"Goodbye\", \"See you later\", \"Take care\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"thanks\",\n",
    "        \"patterns\": [\"Thank you\", \"Thanks\", \"Thanks a lot\", \"I appreciate it\"],\n",
    "        \"responses\": [\"You're welcome\", \"No problem\", \"Glad I could help\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"about\",\n",
    "        \"patterns\": [\"What can you do\", \"Who are you\", \"What are you\", \"What is your purpose\"],\n",
    "        \"responses\": [\"I am a chatbot\", \"My purpose is to assist you\", \"I can answer questions and provide assistance\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"help\",\n",
    "        \"patterns\": [\"Help\", \"I need help\", \"Can you help me\", \"What should I do\"],\n",
    "        \"responses\": [\"Sure, what do you need help with?\", \"I'm here to help. What's the problem?\", \"How can I assist you?\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"age\",\n",
    "        \"patterns\": [\"How old are you\", \"What's your age\"],\n",
    "        \"responses\": [\"I don't have an age. I'm a chatbot.\", \"I was just born in the digital world.\", \"Age is just a number for me.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"weather\",\n",
    "        \"patterns\": [\"What's the weather like\", \"How's the weather today\"],\n",
    "        \"responses\": [\"I'm sorry, I cannot provide real-time weather information.\", \"You can check the weather on a weather app or website.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"budget\",\n",
    "        \"patterns\": [\"How can I make a budget\", \"What's a good budgeting strategy\", \"How do I create a budget\"],\n",
    "        \"responses\": [\"To make a budget, start by tracking your income and expenses. Then, allocate your income towards essential expenses like rent, food, and bills. Next, allocate some of your income towards savings and debt repayment. Finally, allocate the remainder of your income towards discretionary expenses like entertainment and hobbies.\", \"A good budgeting strategy is to use the 50/30/20 rule. This means allocating 50% of your income towards essential expenses, 30% towards discretionary expenses, and 20% towards savings and debt repayment.\", \"To create a budget, start by setting financial goals for yourself. Then, track your income and expenses for a few months to get a sense of where your money is going. Next, create a budget by allocating your income towards essential expenses, savings and debt repayment, and discretionary expenses.\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"credit_score\",\n",
    "        \"patterns\": [\"What is a credit score\", \"How do I check my credit score\", \"How can I improve my credit score\"],\n",
    "        \"responses\": [\"A credit score is a number that represents your creditworthiness. It is based on your credit history and is used by lenders to determine whether or not to lend you money. The higher your credit score, the more likely you are to be approved for credit.\", \"You can check your credit score for free on several websites such as Credit Karma and Credit Sesame.\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f5c0bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the vectorizer and classifier\n",
    "vectorizer = TfidfVectorizer()\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000)\n",
    "\n",
    "# Preprocess the data\n",
    "tags = []\n",
    "patterns = []\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        tags.append(intent['tag'])\n",
    "        patterns.append(pattern)\n",
    "\n",
    "# training the model\n",
    "x = vectorizer.fit_transform(patterns)\n",
    "y = tags\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f22ff7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(input_text):\n",
    "    input_text = vectorizer.transform([input_text])\n",
    "    tag = clf.predict(input_text)[0]\n",
    "    for intent in intents:\n",
    "        if intent['tag'] == tag:\n",
    "            response = random.choice(intent['responses'])\n",
    "            return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "594205d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 12:59:17.193 \n",
      "  Warning: to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-26 12:59:17.199 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "def main():\n",
    "    global counter\n",
    "    st.title(\"iPEC-Chatbot\")\n",
    "    st.write(\"Welcome to the chatbot. Please type a message and press Enter to start the conversation.\")\n",
    "\n",
    "    counter += 1\n",
    "    user_input = st.text_input(\"You:\", key=f\"user_input_{counter}\")\n",
    "\n",
    "    if user_input:\n",
    "        response = chatbot(user_input)\n",
    "        st.text_area(\"iPEC-Chatbot:\", value=response, height=100, max_chars=None, key=f\"chatbot_response_{counter}\")\n",
    "\n",
    "        if response.lower() in ['goodbye', 'bye']:\n",
    "            st.write(\"Thank you for chatting with me. Have a great day!\")\n",
    "            st.stop()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f0dc8",
   "metadata": {},
   "source": [
    "# Chatbot-6 API based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af6c2af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in d:\\anaconda\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in d:\\anaconda\\lib\\site-packages (from pyttsx3) (1.4.11)\n",
      "Requirement already satisfied: pypiwin32 in d:\\anaconda\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in d:\\anaconda\\lib\\site-packages (from pyttsx3) (305.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e2b9ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in d:\\anaconda\\lib\\site-packages (3.14.3)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from SpeechRecognition) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4388b58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wolframalpha in d:\\anaconda\\lib\\site-packages (5.1.3)\n",
      "Requirement already satisfied: xmltodict in d:\\anaconda\\lib\\site-packages (from wolframalpha) (0.14.2)\n",
      "Requirement already satisfied: more-itertools in d:\\anaconda\\lib\\site-packages (from wolframalpha) (10.3.0)\n",
      "Requirement already satisfied: jaraco.context in d:\\anaconda\\lib\\site-packages (from wolframalpha) (6.0.1)\n",
      "Requirement already satisfied: httpx in d:\\anaconda\\lib\\site-packages (from wolframalpha) (0.27.0)\n",
      "Requirement already satisfied: multidict in d:\\anaconda\\lib\\site-packages (from wolframalpha) (6.0.4)\n",
      "Requirement already satisfied: anyio in d:\\anaconda\\lib\\site-packages (from httpx->wolframalpha) (4.2.0)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\lib\\site-packages (from httpx->wolframalpha) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\lib\\site-packages (from httpx->wolframalpha) (1.0.2)\n",
      "Requirement already satisfied: idna in d:\\anaconda\\lib\\site-packages (from httpx->wolframalpha) (3.7)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\lib\\site-packages (from httpx->wolframalpha) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx->wolframalpha) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wolframalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd50426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11705 sha256=72a669a8afa66d1ce7092e99afcd46f711136de9075e2eb3cefeee78f84f7a93\n",
      "  Stored in directory: c:\\users\\vkram\\appdata\\local\\pip\\cache\\wheels\\63\\47\\7c\\a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a36c24ae-583a-4b4a-834e-57ae9f60d9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3cc42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python package supporting common text-to-speech engines\n",
    "import pyttsx3\n",
    "  \n",
    "# For understanding speech\n",
    "import speech_recognition as sr\n",
    "  \n",
    "# For fetching the answers to computational queries\n",
    "import wolframalpha\n",
    "  \n",
    "# for fetching wikipedia articles\n",
    "import wikipedia\n",
    "# Function to search the query that is either entered or spoken by user\n",
    "def search(query):\n",
    "      \n",
    "    # try is used for searching with wolframAlpha\n",
    "    try:\n",
    "          \n",
    "        # Generate your App ID from WolframAlpha \n",
    "        app_id = \"Your WolframAlpha App ID here\"\n",
    "        client = wolframalpha.Client(ULVYEJ-KXH8TGLUR9)\n",
    "        res = client.query(query)\n",
    "        answer = next(res.results).text\n",
    "        print(answer)\n",
    "        SpeakText(\"Your answer is \" + answer)\n",
    "          \n",
    "    # If the query cannot be searched using WolframAlpha then it is searched in wikipedia\n",
    "    except:\n",
    "          \n",
    "        query = query.split(' ') \n",
    "        query = \" \".join(query[0:])\n",
    "          \n",
    "        SpeakText(\"iPEC Robo is searching for \" + query)\n",
    "        print(wikipedia.summary(query, sentences = 3))\n",
    "        SpeakText(wikipedia.summary(query, \n",
    "                                      sentences = 3))\n",
    "        # Function to convert text to \n",
    "# speech \n",
    "def SpeakText(command): \n",
    "        \n",
    "    # Initialize the engine \n",
    "    engine = pyttsx3.init() \n",
    "    engine.say(command)  \n",
    "    engine.runAndWait()\n",
    "    # Driver's code\n",
    "# input query from the user by \n",
    "# typing or by voice\n",
    "query = input()\n",
    "query = query.lower()\n",
    "  \n",
    "# if query is blank then user \n",
    "# is prompted to speak something.\n",
    "if query == '': \n",
    "    r = sr.Recognizer()\n",
    "  \n",
    "    # uses the default microphone\n",
    "    # as the source to record voice\n",
    "    with sr.Microphone() as source:  \n",
    "        print(\"Say Something \")\n",
    "  \n",
    "        # reduces the background disturbances\n",
    "        # and noise for 2 seconds\n",
    "        r.adjust_for_ambient_noise(source, 2)  \n",
    "          \n",
    "        # listening to source\n",
    "        audio = r.listen(source)  \n",
    "    try:\n",
    "        speech = r.recognize_google(audio)\n",
    "        search(speech)\n",
    "  \n",
    "    # Handling Exceptions if speech \n",
    "    # is not understood.\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not \\\n",
    "        understand audio\")\n",
    "  \n",
    "    # Couldn't handle requests, occurs \n",
    "    # mainly because of network errors\n",
    "    except sr.RequestError as e:  \n",
    "        print(\"Could not request results from Google \\\n",
    "        Speech Recognition service;{0}\".format(e))\n",
    "else:\n",
    "    search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09474c",
   "metadata": {},
   "source": [
    "# 7.Chatbot Design with Keras & Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fb6eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8220c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []  \n",
    "responses = []\n",
    "\n",
    "\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        training_sentences.append(pattern)\n",
    "        training_labels.append(intent['tag'])\n",
    "    responses.append(intent['responses'])\n",
    "    \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "        \n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef87db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_encoder = LabelEncoder()\n",
    "lbl_encoder.fit(training_labels)\n",
    "training_labels = lbl_encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73df0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_len = 20\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3aac2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d_1           │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.1562 - loss: 2.078 ━━━━━━━━━━━━━━━━━━━━ 4s 61ms/step - accuracy: 0.1531 - loss: 2.0786\n",
      "Epoch 2/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.1562 - loss: 2.076 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.1531 - loss: 2.0767\n",
      "Epoch 3/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.1562 - loss: 2.076 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1531 - loss: 2.0759\n",
      "Epoch 4/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.075 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1531 - loss: 2.0748\n",
      "Epoch 5/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.1562 - loss: 2.072 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1531 - loss: 2.0732\n",
      "Epoch 6/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1562 - loss: 2.072 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1531 - loss: 2.0723\n",
      "Epoch 7/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1562 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1531 - loss: 2.0712\n",
      "Epoch 8/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.1562 - loss: 2.070 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1531 - loss: 2.0708\n",
      "Epoch 9/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1250 - loss: 2.071 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1427 - loss: 2.0711\n",
      "Epoch 10/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1562 - loss: 2.069 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.1531 - loss: 2.0697\n",
      "Epoch 11/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1562 - loss: 2.067 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1531 - loss: 2.0681\n",
      "Epoch 12/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1562 - loss: 2.067 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.1531 - loss: 2.0674\n",
      "Epoch 13/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1250 - loss: 2.068 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.1427 - loss: 2.0670\n",
      "Epoch 14/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1250 - loss: 2.067 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1427 - loss: 2.0658\n",
      "Epoch 15/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 99ms/step - accuracy: 0.1562 - loss: 2.064 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.1531 - loss: 2.0639\n",
      "Epoch 16/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1562 - loss: 2.063 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.1531 - loss: 2.0626\n",
      "Epoch 17/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1562 - loss: 2.059 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.1531 - loss: 2.0603\n",
      "Epoch 18/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1562 - loss: 2.060 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1531 - loss: 2.0595\n",
      "Epoch 19/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.1250 - loss: 2.061 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1427 - loss: 2.0589\n",
      "Epoch 20/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.057 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1531 - loss: 2.0567\n",
      "Epoch 21/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.1562 - loss: 2.055 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.1531 - loss: 2.0547\n",
      "Epoch 22/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.1562 - loss: 2.053 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1531 - loss: 2.0531\n",
      "Epoch 23/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.049 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1531 - loss: 2.0510\n",
      "Epoch 24/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.1250 - loss: 2.056 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.1427 - loss: 2.0524\n",
      "Epoch 25/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.1562 - loss: 2.050 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.1531 - loss: 2.0498\n",
      "Epoch 26/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1562 - loss: 2.045 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.1531 - loss: 2.0472\n",
      "Epoch 27/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.1250 - loss: 2.053 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.1427 - loss: 2.0489\n",
      "Epoch 28/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.1562 - loss: 2.039 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.1531 - loss: 2.0439\n",
      "Epoch 29/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.1250 - loss: 2.052 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.1427 - loss: 2.0475\n",
      "Epoch 30/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1562 - loss: 2.045 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.1531 - loss: 2.0451\n",
      "Epoch 31/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.1562 - loss: 2.045 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.1531 - loss: 2.0443\n",
      "Epoch 32/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.1562 - loss: 2.035 ━━━━━━━━━━━━━━━━━━━━ 0s 99ms/step - accuracy: 0.1531 - loss: 2.0406\n",
      "Epoch 33/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.1250 - loss: 2.051 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.1427 - loss: 2.0448\n",
      "Epoch 34/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.1562 - loss: 2.043 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1531 - loss: 2.0418\n",
      "Epoch 35/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1562 - loss: 2.042 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1531 - loss: 2.0408\n",
      "Epoch 36/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1562 - loss: 2.030 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.1531 - loss: 2.0362\n",
      "Epoch 37/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.1531 - loss: 2.0353\n",
      "Epoch 38/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.1250 - loss: 2.047 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.1427 - loss: 2.0408\n",
      "Epoch 39/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.1562 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1531 - loss: 2.0342\n",
      "Epoch 40/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1562 - loss: 2.039 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1531 - loss: 2.0375\n",
      "Epoch 41/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.1562 - loss: 2.039 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.1531 - loss: 2.0370\n",
      "Epoch 42/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.1562 - loss: 2.037 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1531 - loss: 2.0359\n",
      "Epoch 43/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.1562 - loss: 2.037 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1531 - loss: 2.0355\n",
      "Epoch 44/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1562 - loss: 2.025 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.1531 - loss: 2.0306\n",
      "Epoch 45/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1562 - loss: 2.022 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1531 - loss: 2.0289\n",
      "Epoch 46/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.1250 - loss: 2.042 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.1427 - loss: 2.0351\n",
      "Epoch 47/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1562 - loss: 2.021 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.1531 - loss: 2.0278\n",
      "Epoch 48/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.1562 - loss: 2.023 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.1531 - loss: 2.0283\n",
      "Epoch 49/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.1562 - loss: 2.019 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.1531 - loss: 2.0267\n",
      "Epoch 50/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1562 - loss: 2.023 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.1531 - loss: 2.0280\n",
      "Epoch 51/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 223ms/step - accuracy: 0.1562 - loss: 2.01 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.1531 - loss: 2.0267 \n",
      "Epoch 52/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.1562 - loss: 2.020 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.1531 - loss: 2.0271\n",
      "Epoch 53/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1531 - loss: 2.0307\n",
      "Epoch 54/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.1562 - loss: 2.030 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.1531 - loss: 2.0311\n",
      "Epoch 55/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1562 - loss: 2.030 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.1531 - loss: 2.0315\n",
      "Epoch 56/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.1562 - loss: 2.034 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1531 - loss: 2.0330\n",
      "Epoch 57/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.1562 - loss: 2.035 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.1531 - loss: 2.0331\n",
      "Epoch 58/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1562 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.1531 - loss: 2.0305\n",
      "Epoch 59/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.027 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.1531 - loss: 2.0302\n",
      "Epoch 60/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1562 - loss: 2.031 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1531 - loss: 2.0315\n",
      "Epoch 61/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.1562 - loss: 2.031 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1531 - loss: 2.0314\n",
      "Epoch 62/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1562 - loss: 2.034 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.1531 - loss: 2.0325\n",
      "Epoch 63/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.1562 - loss: 2.033 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1531 - loss: 2.0320\n",
      "Epoch 64/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1250 - loss: 2.037 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.1427 - loss: 2.0329\n",
      "Epoch 65/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.1562 - loss: 2.031 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.1531 - loss: 2.0305\n",
      "Epoch 66/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1562 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1531 - loss: 2.0290\n",
      "Epoch 67/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.1562 - loss: 2.021 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.1531 - loss: 2.0257\n",
      "Epoch 68/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1562 - loss: 2.022 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.1531 - loss: 2.0253\n",
      "Epoch 69/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1562 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1531 - loss: 2.0275\n",
      "Epoch 70/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1562 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.1531 - loss: 2.0265\n",
      "Epoch 71/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1562 - loss: 2.018 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.1531 - loss: 2.0231\n",
      "Epoch 72/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.1562 - loss: 2.015 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1531 - loss: 2.0216\n",
      "Epoch 73/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1562 - loss: 2.026 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.1531 - loss: 2.0251\n",
      "Epoch 74/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1562 - loss: 2.024 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1531 - loss: 2.0243\n",
      "Epoch 75/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1250 - loss: 2.029 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.1427 - loss: 2.0258\n",
      "Epoch 76/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.1562 - loss: 2.016 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.1531 - loss: 2.0210\n",
      "Epoch 77/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1562 - loss: 2.025 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1531 - loss: 2.0232\n",
      "Epoch 78/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.1250 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1427 - loss: 2.0239\n",
      "Epoch 79/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.016 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.1531 - loss: 2.0192\n",
      "Epoch 80/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.1562 - loss: 2.015 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.1531 - loss: 2.0183\n",
      "Epoch 81/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1562 - loss: 2.013 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.1531 - loss: 2.0176\n",
      "Epoch 82/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.1562 - loss: 2.013 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.1531 - loss: 2.0179\n",
      "Epoch 83/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.1562 - loss: 2.02 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.1531 - loss: 2.0214 \n",
      "Epoch 84/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.1562 - loss: 2.022 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1531 - loss: 2.0212\n",
      "Epoch 85/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.1250 - loss: 2.028 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.1427 - loss: 2.0227\n",
      "Epoch 86/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.1562 - loss: 2.021 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.1531 - loss: 2.0196\n",
      "Epoch 87/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.1562 - loss: 2.020 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1531 - loss: 2.0183\n",
      "Epoch 88/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.1562 - loss: 2.018 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.1531 - loss: 2.0164\n",
      "Epoch 89/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.1250 - loss: 2.022 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.1427 - loss: 2.0167\n",
      "Epoch 90/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.1562 - loss: 2.015 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.1531 - loss: 2.0128\n",
      "Epoch 91/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.1562 - loss: 2.013 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.1531 - loss: 2.0111\n",
      "Epoch 92/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.1562 - loss: 2.000 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.1531 - loss: 2.0059\n",
      "Epoch 93/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1562 - loss: 1.994 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1531 - loss: 2.0031\n",
      "Epoch 94/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1562 - loss: 2.005 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.1531 - loss: 2.0061\n",
      "Epoch 95/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 42ms/step - accuracy: 0.1562 - loss: 1.999 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.1531 - loss: 2.0038\n",
      "Epoch 96/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.1562 - loss: 2.010 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.1531 - loss: 2.0073\n",
      "Epoch 97/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.1562 - loss: 2.010 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.1531 - loss: 2.0066\n",
      "Epoch 98/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.1562 - loss: 2.009 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1531 - loss: 2.0058\n",
      "Epoch 99/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 2.009 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.2143 - loss: 2.0051\n",
      "Epoch 100/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2188 - loss: 1.990 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2143 - loss: 1.9982\n",
      "Epoch 101/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3438 - loss: 1.993 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3368 - loss: 1.9990\n",
      "Epoch 102/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.989 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3674 - loss: 1.9973\n",
      "Epoch 103/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3750 - loss: 2.004 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3674 - loss: 2.0021\n",
      "Epoch 104/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3438 - loss: 2.007 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3570 - loss: 2.0027\n",
      "Epoch 105/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3750 - loss: 2.003 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3674 - loss: 2.0009\n",
      "Epoch 106/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.992 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3674 - loss: 1.9966\n",
      "Epoch 107/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.991 ━━━━━━━━━━━━━━━━━━━━ 0s 117ms/step - accuracy: 0.3674 - loss: 1.9952\n",
      "Epoch 108/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3750 - loss: 1.985 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.9926\n",
      "Epoch 109/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3750 - loss: 1.999 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3674 - loss: 1.9971\n",
      "Epoch 110/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3750 - loss: 1.989 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3674 - loss: 1.9937\n",
      "Epoch 111/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3750 - loss: 1.986 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3674 - loss: 1.9927\n",
      "Epoch 112/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3438 - loss: 1.992 ━━━━━━━━━━━━━━━━━━━━ 0s 99ms/step - accuracy: 0.3368 - loss: 1.9949\n",
      "Epoch 113/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 1.988 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3368 - loss: 1.9939\n",
      "Epoch 114/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3750 - loss: 1.991 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3674 - loss: 1.9954\n",
      "Epoch 115/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3438 - loss: 2.003 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3570 - loss: 2.0003\n",
      "Epoch 116/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3750 - loss: 1.993 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3674 - loss: 1.9972\n",
      "Epoch 117/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 2.004 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3570 - loss: 2.0008\n",
      "Epoch 118/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3750 - loss: 2.000 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.9990\n",
      "Epoch 119/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3438 - loss: 2.003 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3570 - loss: 1.9990\n",
      "Epoch 120/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3438 - loss: 2.000 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.9967\n",
      "Epoch 121/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.987 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3674 - loss: 1.9908\n",
      "Epoch 122/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3438 - loss: 1.996 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.3570 - loss: 1.9924\n",
      "Epoch 123/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3750 - loss: 1.991 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3674 - loss: 1.9893\n",
      "Epoch 124/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3750 - loss: 1.975 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3674 - loss: 1.9828\n",
      "Epoch 125/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3438 - loss: 1.992 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3570 - loss: 1.9874\n",
      "Epoch 126/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3438 - loss: 1.987 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3368 - loss: 1.9850\n",
      "Epoch 127/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.2188 - loss: 1.972 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2143 - loss: 1.9795\n",
      "Epoch 128/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2188 - loss: 1.971 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.2143 - loss: 1.9789\n",
      "Epoch 129/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.2188 - loss: 1.975 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2143 - loss: 1.9803\n",
      "Epoch 130/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2188 - loss: 1.987 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2143 - loss: 1.9844\n",
      "Epoch 131/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.1875 - loss: 1.991 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2039 - loss: 1.9855\n",
      "Epoch 132/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.1875 - loss: 1.991 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.2039 - loss: 1.9845\n",
      "Epoch 133/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.1875 - loss: 1.990 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2039 - loss: 1.9834\n",
      "Epoch 134/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.2188 - loss: 1.983 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.2143 - loss: 1.9802\n",
      "Epoch 135/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2188 - loss: 1.982 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2143 - loss: 1.9787\n",
      "Epoch 136/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2188 - loss: 1.981 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.2143 - loss: 1.9774\n",
      "Epoch 137/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2188 - loss: 1.966 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.2143 - loss: 1.9710\n",
      "Epoch 138/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2188 - loss: 1.977 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.2143 - loss: 1.9731\n",
      "Epoch 139/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.2188 - loss: 1.974 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2143 - loss: 1.9708\n",
      "Epoch 140/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.2188 - loss: 1.976 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.2143 - loss: 1.9702\n",
      "Epoch 141/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2812 - loss: 1.952 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.2756 - loss: 1.9625\n",
      "Epoch 142/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3750 - loss: 1.955 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3674 - loss: 1.9628\n",
      "Epoch 143/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.976 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3570 - loss: 1.9689\n",
      "Epoch 144/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3750 - loss: 1.956 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3674 - loss: 1.9617\n",
      "Epoch 145/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.948 ━━━━━━━━━━━━━━━━━━━━ 0s 108ms/step - accuracy: 0.3674 - loss: 1.9588\n",
      "Epoch 146/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3125 - loss: 1.974 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.3264 - loss: 1.9674\n",
      "Epoch 147/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3438 - loss: 1.955 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3368 - loss: 1.9598\n",
      "Epoch 148/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3438 - loss: 1.965 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3368 - loss: 1.9624\n",
      "Epoch 149/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.3125 - loss: 1.96 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.3264 - loss: 1.9621 \n",
      "Epoch 150/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.961 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3674 - loss: 1.9576\n",
      "Epoch 151/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 106ms/step - accuracy: 0.3750 - loss: 1.94 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3674 - loss: 1.9513 \n",
      "Epoch 152/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3438 - loss: 1.964 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.3570 - loss: 1.9563\n",
      "Epoch 153/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.942 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3674 - loss: 1.9482\n",
      "Epoch 154/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.956 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3674 - loss: 1.9519\n",
      "Epoch 155/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3125 - loss: 1.936 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3078 - loss: 1.942 ━━━━━━━━━━━━━━━━━━━━ 0s 117ms/step - accuracy: 0.3062 - loss: 1.9448\n",
      "Epoch 156/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.2812 - loss: 1.961 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.2958 - loss: 1.9521\n",
      "Epoch 157/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.2812 - loss: 1.953 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.2756 - loss: 1.9486\n",
      "Epoch 158/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.2500 - loss: 1.938 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.2449 - loss: 1.9429\n",
      "Epoch 159/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.2500 - loss: 1.953 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2449 - loss: 1.9472\n",
      "Epoch 160/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2812 - loss: 1.934 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.2756 - loss: 1.9395\n",
      "Epoch 161/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3750 - loss: 1.933 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3674 - loss: 1.9375\n",
      "Epoch 162/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3750 - loss: 1.926 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3674 - loss: 1.9339\n",
      "Epoch 163/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.3750 - loss: 1.944 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3674 - loss: 1.9397\n",
      "Epoch 164/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3750 - loss: 1.931 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.9349\n",
      "Epoch 165/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3438 - loss: 1.949 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3570 - loss: 1.9410\n",
      "Epoch 166/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3125 - loss: 1.948 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3264 - loss: 1.9416\n",
      "Epoch 167/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.2812 - loss: 1.946 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2958 - loss: 1.9404\n",
      "Epoch 168/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3125 - loss: 1.931 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3062 - loss: 1.9338\n",
      "Epoch 169/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3438 - loss: 1.928 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3368 - loss: 1.9308\n",
      "Epoch 170/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3125 - loss: 1.940 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3264 - loss: 1.9331\n",
      "Epoch 171/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3438 - loss: 1.918 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3368 - loss: 1.9243\n",
      "Epoch 172/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3750 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3674 - loss: 1.9242\n",
      "Epoch 173/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3750 - loss: 1.930 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3674 - loss: 1.9252\n",
      "Epoch 174/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.928 ━━━━━━━━━━━━━━━━━━━━ 0s 107ms/step - accuracy: 0.3674 - loss: 1.9233\n",
      "Epoch 175/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3750 - loss: 1.916 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.3674 - loss: 1.9185\n",
      "Epoch 176/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3438 - loss: 1.930 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3570 - loss: 1.9226\n",
      "Epoch 177/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3750 - loss: 1.926 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3674 - loss: 1.9205\n",
      "Epoch 178/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.3750 - loss: 1.925 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3674 - loss: 1.9195\n",
      "Epoch 179/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3750 - loss: 1.894 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3674 - loss: 1.9095\n",
      "Epoch 180/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3438 - loss: 1.926 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3570 - loss: 1.9192\n",
      "Epoch 181/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3750 - loss: 1.892 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3674 - loss: 1.9064\n",
      "Epoch 182/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.3438 - loss: 1.925 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3570 - loss: 1.9160\n",
      "Epoch 183/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3438 - loss: 1.922 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.9133\n",
      "Epoch 184/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3750 - loss: 1.894 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3674 - loss: 1.9036\n",
      "Epoch 185/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3125 - loss: 1.890 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3062 - loss: 1.9006\n",
      "Epoch 186/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 109ms/step - accuracy: 0.2500 - loss: 1.89 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.2449 - loss: 1.8987 \n",
      "Epoch 187/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.2812 - loss: 1.906 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.2958 - loss: 1.8987\n",
      "Epoch 188/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.3125 - loss: 1.875 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3062 - loss: 1.8853\n",
      "Epoch 189/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.2812 - loss: 1.884 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.2756 - loss: 1.8871\n",
      "Epoch 190/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.2812 - loss: 1.882 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.2756 - loss: 1.8855\n",
      "Epoch 191/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3438 - loss: 1.875 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3368 - loss: 1.8814\n",
      "Epoch 192/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 93ms/step - accuracy: 0.3750 - loss: 1.873 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3674 - loss: 1.8788\n",
      "Epoch 193/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3438 - loss: 1.891 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3570 - loss: 1.8839\n",
      "Epoch 194/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.882 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3674 - loss: 1.8792\n",
      "Epoch 195/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.859 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.8694\n",
      "Epoch 196/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3438 - loss: 1.886 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3570 - loss: 1.8766\n",
      "Epoch 197/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 223ms/step - accuracy: 0.3750 - loss: 1.85 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.8647 \n",
      "Epoch 198/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3125 - loss: 1.862 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3062 - loss: 1.8663\n",
      "Epoch 199/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3125 - loss: 1.878 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3264 - loss: 1.8696\n",
      "Epoch 200/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.3750 - loss: 1.857 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3674 - loss: 1.8606\n",
      "Epoch 201/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3438 - loss: 1.875 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3570 - loss: 1.8646\n",
      "Epoch 202/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3750 - loss: 1.863 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3674 - loss: 1.8585\n",
      "Epoch 203/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3750 - loss: 1.842 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3674 - loss: 1.8498\n",
      "Epoch 204/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.3438 - loss: 1.864 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.8545\n",
      "Epoch 205/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.854 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3674 - loss: 1.8484\n",
      "Epoch 206/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.3438 - loss: 1.854 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.8465\n",
      "Epoch 207/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 107ms/step - accuracy: 0.3750 - loss: 1.83 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3674 - loss: 1.8405 \n",
      "Epoch 208/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3125 - loss: 1.837 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3062 - loss: 1.8390\n",
      "Epoch 209/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3438 - loss: 1.851 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.8418\n",
      "Epoch 210/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.823 ━━━━━━━━━━━━━━━━━━━━ 0s 107ms/step - accuracy: 0.3674 - loss: 1.8303\n",
      "Epoch 211/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3438 - loss: 1.837 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3570 - loss: 1.8322\n",
      "Epoch 212/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3750 - loss: 1.833 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3674 - loss: 1.8273\n",
      "Epoch 213/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.3750 - loss: 1.818 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3674 - loss: 1.8198\n",
      "Epoch 214/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.796 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.8117\n",
      "Epoch 215/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3438 - loss: 1.830 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.3570 - loss: 1.8221\n",
      "Epoch 216/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.801 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.8101\n",
      "Epoch 217/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.3750 - loss: 1.787 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3674 - loss: 1.8015\n",
      "Epoch 218/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3750 - loss: 1.803 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3674 - loss: 1.8035\n",
      "Epoch 219/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3750 - loss: 1.797 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3674 - loss: 1.7984\n",
      "Epoch 220/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3750 - loss: 1.786 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3674 - loss: 1.7931\n",
      "Epoch 221/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.775 ━━━━━━━━━━━━━━━━━━━━ 0s 105ms/step - accuracy: 0.3674 - loss: 1.7882\n",
      "Epoch 222/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3438 - loss: 1.799 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.7954\n",
      "Epoch 223/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3750 - loss: 1.789 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.3674 - loss: 1.7904\n",
      "Epoch 224/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3438 - loss: 1.801 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3570 - loss: 1.7933\n",
      "Epoch 225/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3750 - loss: 1.792 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3674 - loss: 1.7871\n",
      "Epoch 226/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3438 - loss: 1.784 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3570 - loss: 1.7803\n",
      "Epoch 227/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.782 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.7762\n",
      "Epoch 228/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3750 - loss: 1.752 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3674 - loss: 1.7642\n",
      "Epoch 229/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.3750 - loss: 1.755 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3674 - loss: 1.7634\n",
      "Epoch 230/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 206ms/step - accuracy: 0.3750 - loss: 1.73 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.3674 - loss: 1.7541 \n",
      "Epoch 231/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3750 - loss: 1.733 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3674 - loss: 1.7492\n",
      "Epoch 232/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step - accuracy: 0.3438 - loss: 1.76 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3570 - loss: 1.7588 \n",
      "Epoch 233/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3750 - loss: 1.733 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3674 - loss: 1.7462\n",
      "Epoch 234/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.750 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.3674 - loss: 1.7499\n",
      "Epoch 235/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3750 - loss: 1.756 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3674 - loss: 1.7501\n",
      "Epoch 236/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 101ms/step - accuracy: 0.3750 - loss: 1.73 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3674 - loss: 1.7406 \n",
      "Epoch 237/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3750 - loss: 1.749 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3674 - loss: 1.7426\n",
      "Epoch 238/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3750 - loss: 1.724 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3674 - loss: 1.7312\n",
      "Epoch 239/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 106ms/step - accuracy: 0.3438 - loss: 1.73 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3570 - loss: 1.7316 \n",
      "Epoch 240/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.707 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3674 - loss: 1.7196\n",
      "Epoch 241/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3438 - loss: 1.731 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3570 - loss: 1.7249\n",
      "Epoch 242/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.715 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.3674 - loss: 1.7156\n",
      "Epoch 243/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.708 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.7088\n",
      "Epoch 244/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3438 - loss: 1.716 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.7081\n",
      "Epoch 245/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3750 - loss: 1.688 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3693 - loss: 1.694 ━━━━━━━━━━━━━━━━━━━━ 0s 119ms/step - accuracy: 0.3674 - loss: 1.6963\n",
      "Epoch 246/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3438 - loss: 1.703 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3570 - loss: 1.6982\n",
      "Epoch 247/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3438 - loss: 1.702 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.6940\n",
      "Epoch 248/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.3438 - loss: 1.696 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3570 - loss: 1.6883\n",
      "Epoch 249/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3750 - loss: 1.654 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.6728\n",
      "Epoch 250/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3750 - loss: 1.690 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3674 - loss: 1.6824\n",
      "Epoch 251/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3438 - loss: 1.682 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3570 - loss: 1.6766\n",
      "Epoch 252/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.3438 - loss: 1.688 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3570 - loss: 1.6749\n",
      "Epoch 253/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3750 - loss: 1.647 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3674 - loss: 1.6574\n",
      "Epoch 254/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3438 - loss: 1.663 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3570 - loss: 1.6575\n",
      "Epoch 255/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3750 - loss: 1.634 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.3693 - loss: 1.640 ━━━━━━━━━━━━━━━━━━━━ 0s 108ms/step - accuracy: 0.3674 - loss: 1.6422\n",
      "Epoch 256/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3750 - loss: 1.657 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3674 - loss: 1.6504\n",
      "Epoch 257/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3438 - loss: 1.664 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3368 - loss: 1.6570\n",
      "Epoch 258/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3125 - loss: 1.668 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3264 - loss: 1.6606\n",
      "Epoch 259/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3125 - loss: 1.664 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3264 - loss: 1.6589\n",
      "Epoch 260/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3438 - loss: 1.647 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3368 - loss: 1.6467\n",
      "Epoch 261/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.3125 - loss: 1.650 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3264 - loss: 1.6373\n",
      "Epoch 262/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.3750 - loss: 1.619 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3674 - loss: 1.6189\n",
      "Epoch 263/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3438 - loss: 1.632 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3570 - loss: 1.6186\n",
      "Epoch 264/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.3438 - loss: 1.628 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3570 - loss: 1.6162\n",
      "Epoch 265/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3750 - loss: 1.628 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3674 - loss: 1.6186\n",
      "Epoch 266/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3438 - loss: 1.633 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3570 - loss: 1.6263\n",
      "Epoch 267/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.609 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3674 - loss: 1.6205\n",
      "Epoch 268/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3438 - loss: 1.627 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3570 - loss: 1.6193\n",
      "Epoch 269/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.3438 - loss: 1.62 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.6068 \n",
      "Epoch 270/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3750 - loss: 1.556 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.5761\n",
      "Epoch 271/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3438 - loss: 1.594 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.3570 - loss: 1.5820\n",
      "Epoch 272/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3438 - loss: 1.581 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.3537 - loss: 1.574 ━━━━━━━━━━━━━━━━━━━━ 0s 111ms/step - accuracy: 0.3570 - loss: 1.5720\n",
      "Epoch 273/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.3438 - loss: 1.580 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.3570 - loss: 1.5679\n",
      "Epoch 274/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.3438 - loss: 1.577 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.5639\n",
      "Epoch 275/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3750 - loss: 1.552 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3674 - loss: 1.5554\n",
      "Epoch 276/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3438 - loss: 1.578 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3570 - loss: 1.5632\n",
      "Epoch 277/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3438 - loss: 1.580 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.5643\n",
      "Epoch 278/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3750 - loss: 1.543 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3674 - loss: 1.5575\n",
      "Epoch 279/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3750 - loss: 1.559 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3674 - loss: 1.5634\n",
      "Epoch 280/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 218ms/step - accuracy: 0.3750 - loss: 1.54 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3674 - loss: 1.5495 \n",
      "Epoch 281/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3750 - loss: 1.525 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3674 - loss: 1.5333\n",
      "Epoch 282/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3750 - loss: 1.533 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.3674 - loss: 1.5298\n",
      "Epoch 283/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3750 - loss: 1.496 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.5145\n",
      "Epoch 284/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3750 - loss: 1.529 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3674 - loss: 1.5247\n",
      "Epoch 285/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3438 - loss: 1.532 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3570 - loss: 1.5240\n",
      "Epoch 286/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.3438 - loss: 1.536 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3570 - loss: 1.5217\n",
      "Epoch 287/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.3750 - loss: 1.512 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.3674 - loss: 1.5063\n",
      "Epoch 288/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3750 - loss: 1.500 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3674 - loss: 1.4930\n",
      "Epoch 289/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.3750 - loss: 1.451 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.3674 - loss: 1.4700\n",
      "Epoch 290/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3438 - loss: 1.498 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.3570 - loss: 1.4824\n",
      "Epoch 291/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 95ms/step - accuracy: 0.3750 - loss: 1.470 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.3674 - loss: 1.4736\n",
      "Epoch 292/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3750 - loss: 1.488 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3674 - loss: 1.4791\n",
      "Epoch 293/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.3438 - loss: 1.480 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.3570 - loss: 1.4739\n",
      "Epoch 294/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.3750 - loss: 1.462 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3674 - loss: 1.4639\n",
      "Epoch 295/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.3750 - loss: 1.444 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.3674 - loss: 1.4543\n",
      "Epoch 296/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.4688 - loss: 1.418 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.4593 - loss: 1.4422\n",
      "Epoch 297/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.4375 - loss: 1.468 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.4489 - loss: 1.4577\n",
      "Epoch 298/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.4688 - loss: 1.440 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.4593 - loss: 1.4496\n",
      "Epoch 299/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.4062 - loss: 1.470 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.4182 - loss: 1.4620\n",
      "Epoch 300/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.4375 - loss: 1.435 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4287 - loss: 1.4513\n",
      "Epoch 301/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.4062 - loss: 1.468 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.4182 - loss: 1.4612\n",
      "Epoch 302/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4062 - loss: 1.457 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.4182 - loss: 1.4494\n",
      "Epoch 303/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.4375 - loss: 1.440 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.4489 - loss: 1.4311\n",
      "Epoch 304/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4375 - loss: 1.423 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4489 - loss: 1.4162\n",
      "Epoch 305/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.4375 - loss: 1.421 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.4489 - loss: 1.4110\n",
      "Epoch 306/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4688 - loss: 1.405 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.4593 - loss: 1.4079\n",
      "Epoch 307/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4375 - loss: 1.435 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.4489 - loss: 1.4212\n",
      "Epoch 308/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 97ms/step - accuracy: 0.4688 - loss: 1.410 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.4593 - loss: 1.4165\n",
      "Epoch 309/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.4688 - loss: 1.402 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.4593 - loss: 1.4125\n",
      "Epoch 310/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.4375 - loss: 1.418 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.4489 - loss: 1.4089\n",
      "Epoch 311/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.4375 - loss: 1.370 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.4287 - loss: 1.3833\n",
      "Epoch 312/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4375 - loss: 1.358 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.4287 - loss: 1.3747\n",
      "Epoch 313/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.4062 - loss: 1.403 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.4182 - loss: 1.3926\n",
      "Epoch 314/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.3750 - loss: 1.360 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.3674 - loss: 1.3804\n",
      "Epoch 315/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.3750 - loss: 1.371 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3674 - loss: 1.3801\n",
      "Epoch 316/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.4062 - loss: 1.367 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.3980 - loss: 1.3745\n",
      "Epoch 317/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.3750 - loss: 1.385 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.3876 - loss: 1.3788\n",
      "Epoch 318/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.4062 - loss: 1.362 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.3980 - loss: 1.3688\n",
      "Epoch 319/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.4062 - loss: 1.38 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3980 - loss: 1.3748 \n",
      "Epoch 320/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.4062 - loss: 1.380 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.3980 - loss: 1.3714\n",
      "Epoch 321/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.4062 - loss: 1.373 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.3980 - loss: 1.3643\n",
      "Epoch 322/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.3750 - loss: 1.368 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.3876 - loss: 1.3569\n",
      "Epoch 323/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.4688 - loss: 1.313 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.4593 - loss: 1.3338\n",
      "Epoch 324/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.4688 - loss: 1.362 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.4795 - loss: 1.3485\n",
      "Epoch 325/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.4688 - loss: 1.350 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.4795 - loss: 1.3453\n",
      "Epoch 326/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5000 - loss: 1.359 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.4899 - loss: 1.3482\n",
      "Epoch 327/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5000 - loss: 1.329 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.4899 - loss: 1.3366\n",
      "Epoch 328/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 107ms/step - accuracy: 0.5312 - loss: 1.32 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.5205 - loss: 1.3325 \n",
      "Epoch 329/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.5312 - loss: 1.321 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5205 - loss: 1.3250\n",
      "Epoch 330/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5625 - loss: 1.314 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5511 - loss: 1.3175\n",
      "Epoch 331/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.5312 - loss: 1.301 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.5407 - loss: 1.3105\n",
      "Epoch 332/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.5625 - loss: 1.304 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5511 - loss: 1.3115\n",
      "Epoch 333/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5312 - loss: 1.332 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.5407 - loss: 1.3239\n",
      "Epoch 334/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.5312 - loss: 1.334 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.5407 - loss: 1.3252\n",
      "Epoch 335/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5625 - loss: 1.282 ━━━━━━━━━━━━━━━━━━━━ 0s 120ms/step - accuracy: 0.5511 - loss: 1.3021\n",
      "Epoch 336/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.5625 - loss: 1.286 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.5511 - loss: 1.2945\n",
      "Epoch 337/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.5625 - loss: 1.306 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.5713 - loss: 1.2946\n",
      "Epoch 338/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.5938 - loss: 1.304 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6020 - loss: 1.2921\n",
      "Epoch 339/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.5625 - loss: 1.279 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5713 - loss: 1.2844\n",
      "Epoch 340/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.5938 - loss: 1.265 ━━━━━━━━━━━━━━━━━━━━ 0s 116ms/step - accuracy: 0.5818 - loss: 1.2821\n",
      "Epoch 341/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5938 - loss: 1.287 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.5818 - loss: 1.2914\n",
      "Epoch 342/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5625 - loss: 1.306 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5713 - loss: 1.2967\n",
      "Epoch 343/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.5938 - loss: 1.301 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.5818 - loss: 1.2905\n",
      "Epoch 344/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5938 - loss: 1.267 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6020 - loss: 1.2741\n",
      "Epoch 345/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5938 - loss: 1.272 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.6020 - loss: 1.2689\n",
      "Epoch 346/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6250 - loss: 1.229 ━━━━━━━━━━━━━━━━━━━━ 0s 106ms/step - accuracy: 0.6124 - loss: 1.2480\n",
      "Epoch 347/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6250 - loss: 1.214 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6124 - loss: 1.2384\n",
      "Epoch 348/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.5938 - loss: 1.263 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.6020 - loss: 1.2526\n",
      "Epoch 349/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.5938 - loss: 1.254 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.6020 - loss: 1.2486\n",
      "Epoch 350/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.5938 - loss: 1.251 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6020 - loss: 1.2461\n",
      "Epoch 351/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6250 - loss: 1.215 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6124 - loss: 1.2326\n",
      "Epoch 352/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5938 - loss: 1.240 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6020 - loss: 1.2384\n",
      "Epoch 353/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.5938 - loss: 1.249 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6020 - loss: 1.2369\n",
      "Epoch 354/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.5938 - loss: 1.253 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6020 - loss: 1.2394\n",
      "Epoch 355/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5938 - loss: 1.235 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6020 - loss: 1.2415\n",
      "Epoch 356/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.5938 - loss: 1.277 ━━━━━━━━━━━━━━━━━━━━ 0s 107ms/step - accuracy: 0.6020 - loss: 1.2606\n",
      "Epoch 357/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6250 - loss: 1.224 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6124 - loss: 1.2438\n",
      "Epoch 358/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5938 - loss: 1.252 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.6020 - loss: 1.2455\n",
      "Epoch 359/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.5938 - loss: 1.247 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6020 - loss: 1.2311\n",
      "Epoch 360/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5938 - loss: 1.220 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.6020 - loss: 1.2136\n",
      "Epoch 361/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.5938 - loss: 1.213 ━━━━━━━━━━━━━━━━━━━━ 0s 87ms/step - accuracy: 0.6020 - loss: 1.2059\n",
      "Epoch 362/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6250 - loss: 1.171 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6124 - loss: 1.1903\n",
      "Epoch 363/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5938 - loss: 1.195 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.6020 - loss: 1.1994\n",
      "Epoch 364/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.5938 - loss: 1.216 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6020 - loss: 1.2073\n",
      "Epoch 365/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5938 - loss: 1.201 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6020 - loss: 1.2036\n",
      "Epoch 366/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5938 - loss: 1.229 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.6020 - loss: 1.2133\n",
      "Epoch 367/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.6250 - loss: 1.175 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6124 - loss: 1.1927\n",
      "Epoch 368/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 84ms/step - accuracy: 0.5938 - loss: 1.209 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6020 - loss: 1.1989\n",
      "Epoch 369/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6250 - loss: 1.182 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6124 - loss: 1.1856\n",
      "Epoch 370/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.5938 - loss: 1.198 ━━━━━━━━━━━━━━━━━━━━ 0s 96ms/step - accuracy: 0.6020 - loss: 1.1886\n",
      "Epoch 371/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.5938 - loss: 1.178 ━━━━━━━━━━━━━━━━━━━━ 0s 120ms/step - accuracy: 0.6020 - loss: 1.1814\n",
      "Epoch 372/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6250 - loss: 1.146 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6124 - loss: 1.1709\n",
      "Epoch 373/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6250 - loss: 1.150 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6124 - loss: 1.1691\n",
      "Epoch 374/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.5938 - loss: 1.186 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6020 - loss: 1.1771\n",
      "Epoch 375/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5938 - loss: 1.191 ━━━━━━━━━━━━━━━━━━━━ 0s 98ms/step - accuracy: 0.6020 - loss: 1.1780\n",
      "Epoch 376/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.5938 - loss: 1.195 ━━━━━━━━━━━━━━━━━━━━ 0s 117ms/step - accuracy: 0.6020 - loss: 1.1785\n",
      "Epoch 377/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6250 - loss: 1.156 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6124 - loss: 1.1624\n",
      "Epoch 378/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.5938 - loss: 1.174 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6020 - loss: 1.1650\n",
      "Epoch 379/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.5938 - loss: 1.170 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.6020 - loss: 1.1614\n",
      "Epoch 380/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.5938 - loss: 1.173 ━━━━━━━━━━━━━━━━━━━━ 0s 92ms/step - accuracy: 0.6020 - loss: 1.1639\n",
      "Epoch 381/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 104ms/step - accuracy: 0.5938 - loss: 1.17 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6020 - loss: 1.1638 \n",
      "Epoch 382/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.5938 - loss: 1.184 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6020 - loss: 1.1659\n",
      "Epoch 383/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5938 - loss: 1.177 ━━━━━━━━━━━━━━━━━━━━ 0s 85ms/step - accuracy: 0.6020 - loss: 1.1593\n",
      "Epoch 384/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5938 - loss: 1.171 ━━━━━━━━━━━━━━━━━━━━ 0s 90ms/step - accuracy: 0.6020 - loss: 1.1541\n",
      "Epoch 385/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.5938 - loss: 1.169 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6020 - loss: 1.1509\n",
      "Epoch 386/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.5938 - loss: 1.155 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6020 - loss: 1.1445\n",
      "Epoch 387/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6250 - loss: 1.131 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6124 - loss: 1.1357\n",
      "Epoch 388/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 79ms/step - accuracy: 0.6250 - loss: 1.131 ━━━━━━━━━━━━━━━━━━━━ 0s 91ms/step - accuracy: 0.6124 - loss: 1.1346\n",
      "Epoch 389/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.5938 - loss: 1.150 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6020 - loss: 1.1402\n",
      "Epoch 390/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.5938 - loss: 1.150 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6020 - loss: 1.1404\n",
      "Epoch 391/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6250 - loss: 1.113 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6124 - loss: 1.1302\n",
      "Epoch 392/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6250 - loss: 1.125 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6124 - loss: 1.1317\n",
      "Epoch 393/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.5938 - loss: 1.151 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6020 - loss: 1.1342\n",
      "Epoch 394/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6250 - loss: 1.115 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6124 - loss: 1.1184\n",
      "Epoch 395/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6250 - loss: 1.094 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6124 - loss: 1.1092\n",
      "Epoch 396/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5938 - loss: 1.127 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6020 - loss: 1.1168\n",
      "Epoch 397/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6250 - loss: 1.085 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6124 - loss: 1.0984\n",
      "Epoch 398/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5938 - loss: 1.125 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6020 - loss: 1.1083\n",
      "Epoch 399/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5938 - loss: 1.106 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6020 - loss: 1.0983\n",
      "Epoch 400/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5938 - loss: 1.092 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.6020 - loss: 1.0892\n",
      "Epoch 401/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5938 - loss: 1.076 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6020 - loss: 1.0796\n",
      "Epoch 402/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6250 - loss: 1.060 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6124 - loss: 1.0739\n",
      "Epoch 403/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.6250 - loss: 1.079 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6124 - loss: 1.0819\n",
      "Epoch 404/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5938 - loss: 1.100 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6020 - loss: 1.0879\n",
      "Epoch 405/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 118ms/step - accuracy: 0.5938 - loss: 1.09 ━━━━━━━━━━━━━━━━━━━━ 0s 94ms/step - accuracy: 0.6020 - loss: 1.0845 \n",
      "Epoch 406/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.5938 - loss: 1.067 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.6020 - loss: 1.0734\n",
      "Epoch 407/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6250 - loss: 1.067 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6124 - loss: 1.0710\n",
      "Epoch 408/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5938 - loss: 1.071 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6020 - loss: 1.0679\n",
      "Epoch 409/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5938 - loss: 1.050 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6020 - loss: 1.0548\n",
      "Epoch 410/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.5938 - loss: 1.056 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6020 - loss: 1.0523\n",
      "Epoch 411/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6250 - loss: 1.037 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6124 - loss: 1.0431\n",
      "Epoch 412/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6250 - loss: 1.031 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6124 - loss: 1.0424\n",
      "Epoch 413/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5938 - loss: 1.048 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6020 - loss: 1.0524\n",
      "Epoch 414/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5938 - loss: 1.080 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6020 - loss: 1.0651\n",
      "Epoch 415/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.6250 - loss: 1.054 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6124 - loss: 1.0551\n",
      "Epoch 416/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.6250 - loss: 1.027 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6124 - loss: 1.0442\n",
      "Epoch 417/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6250 - loss: 1.047 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6124 - loss: 1.0469\n",
      "Epoch 418/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6250 - loss: 1.035 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6124 - loss: 1.0381\n",
      "Epoch 419/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.5938 - loss: 1.060 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6020 - loss: 1.0452\n",
      "Epoch 420/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6250 - loss: 1.035 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6326 - loss: 1.0399\n",
      "Epoch 421/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6250 - loss: 1.057 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6326 - loss: 1.0446\n",
      "Epoch 422/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 81ms/step - accuracy: 0.6250 - loss: 1.050 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.6326 - loss: 1.0344\n",
      "Epoch 423/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6875 - loss: 0.974 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.6736 - loss: 1.0029\n",
      "Epoch 424/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6562 - loss: 1.022 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6632 - loss: 1.0146\n",
      "Epoch 425/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6562 - loss: 1.025 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6632 - loss: 1.0127\n",
      "Epoch 426/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step - accuracy: 0.6562 - loss: 1.030 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6632 - loss: 1.0154\n",
      "Epoch 427/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6875 - loss: 0.994 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6736 - loss: 1.0070\n",
      "Epoch 428/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6562 - loss: 1.040 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6632 - loss: 1.0265\n",
      "Epoch 429/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6562 - loss: 1.005 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6430 - loss: 1.0201\n",
      "Epoch 430/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6250 - loss: 1.050 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6326 - loss: 1.0386\n",
      "Epoch 431/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6562 - loss: 1.012 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6430 - loss: 1.0244\n",
      "Epoch 432/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6250 - loss: 1.023 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6326 - loss: 1.0246\n",
      "Epoch 433/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6875 - loss: 1.021 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6938 - loss: 1.0188\n",
      "Epoch 434/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6250 - loss: 1.002 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.6326 - loss: 1.0042\n",
      "Epoch 435/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6562 - loss: 0.976 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6430 - loss: 0.9867\n",
      "Epoch 436/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6562 - loss: 0.984 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6430 - loss: 0.9827\n",
      "Epoch 437/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 70ms/step - accuracy: 0.6875 - loss: 0.975 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.6938 - loss: 0.9789\n",
      "Epoch 438/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.6562 - loss: 0.998 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.6632 - loss: 0.9886\n",
      "Epoch 439/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.5938 - loss: 0.938 ━━━━━━━━━━━━━━━━━━━━ 0s 78ms/step - accuracy: 0.5818 - loss: 0.9696\n",
      "Epoch 440/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.5938 - loss: 0.955 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.5818 - loss: 0.9709\n",
      "Epoch 441/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.5625 - loss: 0.992 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5713 - loss: 0.9759\n",
      "Epoch 442/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6250 - loss: 0.961 ━━━━━━━━━━━━━━━━━━━━ 0s 113ms/step - accuracy: 0.6124 - loss: 0.9608\n",
      "Epoch 443/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 80ms/step - accuracy: 0.6250 - loss: 0.933 ━━━━━━━━━━━━━━━━━━━━ 0s 102ms/step - accuracy: 0.6124 - loss: 0.9491\n",
      "Epoch 444/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 76ms/step - accuracy: 0.6875 - loss: 0.970 ━━━━━━━━━━━━━━━━━━━━ 0s 86ms/step - accuracy: 0.6938 - loss: 0.9569\n",
      "Epoch 445/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6562 - loss: 0.943 ━━━━━━━━━━━━━━━━━━━━ 0s 71ms/step - accuracy: 0.6632 - loss: 0.9442\n",
      "Epoch 446/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6250 - loss: 0.943 ━━━━━━━━━━━━━━━━━━━━ 0s 75ms/step - accuracy: 0.6326 - loss: 0.9425\n",
      "Epoch 447/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6562 - loss: 0.929 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6430 - loss: 0.9369\n",
      "Epoch 448/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6562 - loss: 0.933 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6632 - loss: 0.9351\n",
      "Epoch 449/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.6250 - loss: 0.954 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6326 - loss: 0.9394\n",
      "Epoch 450/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6250 - loss: 0.949 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6326 - loss: 0.9361\n",
      "Epoch 451/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6250 - loss: 0.921 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.6326 - loss: 0.9251\n",
      "Epoch 452/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 44ms/step - accuracy: 0.6250 - loss: 0.945 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6326 - loss: 0.9321\n",
      "Epoch 453/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6250 - loss: 0.942 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6326 - loss: 0.9292\n",
      "Epoch 454/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6250 - loss: 0.930 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6326 - loss: 0.9226\n",
      "Epoch 455/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6562 - loss: 0.895 ━━━━━━━━━━━━━━━━━━━━ 0s 83ms/step - accuracy: 0.6430 - loss: 0.9084\n",
      "Epoch 456/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6250 - loss: 0.911 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6326 - loss: 0.9124\n",
      "Epoch 457/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.5938 - loss: 0.933 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6020 - loss: 0.9197\n",
      "Epoch 458/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.5938 - loss: 0.938 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.6020 - loss: 0.9230\n",
      "Epoch 459/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5938 - loss: 0.918 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6020 - loss: 0.9180\n",
      "Epoch 460/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.5938 - loss: 0.919 ━━━━━━━━━━━━━━━━━━━━ 0s 72ms/step - accuracy: 0.6020 - loss: 0.9165\n",
      "Epoch 461/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 48ms/step - accuracy: 0.6250 - loss: 0.892 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6124 - loss: 0.9033\n",
      "Epoch 462/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5938 - loss: 0.924 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6020 - loss: 0.9087\n",
      "Epoch 463/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.5938 - loss: 0.898 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6020 - loss: 0.8956\n",
      "Epoch 464/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.5938 - loss: 0.910 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6020 - loss: 0.8966\n",
      "Epoch 465/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.5938 - loss: 0.906 ━━━━━━━━━━━━━━━━━━━━ 0s 52ms/step - accuracy: 0.6020 - loss: 0.8938\n",
      "Epoch 466/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 63ms/step - accuracy: 0.6250 - loss: 0.856 ━━━━━━━━━━━━━━━━━━━━ 0s 66ms/step - accuracy: 0.6124 - loss: 0.8762\n",
      "Epoch 467/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.5938 - loss: 0.903 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6020 - loss: 0.8898\n",
      "Epoch 468/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.5938 - loss: 0.880 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6020 - loss: 0.8823\n",
      "Epoch 469/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5938 - loss: 0.891 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6020 - loss: 0.8881\n",
      "Epoch 470/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.5938 - loss: 0.908 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6020 - loss: 0.8950\n",
      "Epoch 471/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.5938 - loss: 0.903 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.6020 - loss: 0.8917\n",
      "Epoch 472/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.5938 - loss: 0.898 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6020 - loss: 0.8856\n",
      "Epoch 473/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6250 - loss: 0.850 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.6124 - loss: 0.8661\n",
      "Epoch 474/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6250 - loss: 0.853 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6326 - loss: 0.8644\n",
      "Epoch 475/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6562 - loss: 0.851 ━━━━━━━━━━━━━━━━━━━━ 0s 62ms/step - accuracy: 0.6430 - loss: 0.8644\n",
      "Epoch 476/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.6562 - loss: 0.827 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.6430 - loss: 0.8543\n",
      "Epoch 477/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.6562 - loss: 0.843 ━━━━━━━━━━━━━━━━━━━━ 0s 74ms/step - accuracy: 0.6430 - loss: 0.8554\n",
      "Epoch 478/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 99ms/step - accuracy: 0.6562 - loss: 0.840 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.6430 - loss: 0.8496\n",
      "Epoch 479/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.6875 - loss: 0.854 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6938 - loss: 0.8513\n",
      "Epoch 480/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 43ms/step - accuracy: 0.7500 - loss: 0.834 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.7348 - loss: 0.8432\n",
      "Epoch 481/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.7188 - loss: 0.864 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.7244 - loss: 0.8537\n",
      "Epoch 482/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 73ms/step - accuracy: 0.7188 - loss: 0.869 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.7244 - loss: 0.8564\n",
      "Epoch 483/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6562 - loss: 0.869 ━━━━━━━━━━━━━━━━━━━━ 0s 61ms/step - accuracy: 0.6632 - loss: 0.8565\n",
      "Epoch 484/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 46ms/step - accuracy: 0.6875 - loss: 0.805 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.6736 - loss: 0.8345\n",
      "Epoch 485/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 47ms/step - accuracy: 0.7188 - loss: 0.865 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.7244 - loss: 0.8520\n",
      "Epoch 486/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 58ms/step - accuracy: 0.7188 - loss: 0.856 ━━━━━━━━━━━━━━━━━━━━ 0s 89ms/step - accuracy: 0.7244 - loss: 0.8452\n",
      "Epoch 487/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.7188 - loss: 0.826 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.7244 - loss: 0.8323\n",
      "Epoch 488/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6875 - loss: 0.850 ━━━━━━━━━━━━━━━━━━━━ 0s 51ms/step - accuracy: 0.6938 - loss: 0.8385\n",
      "Epoch 489/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6875 - loss: 0.827 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.6938 - loss: 0.8287\n",
      "Epoch 490/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - accuracy: 0.7188 - loss: 0.808 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.7042 - loss: 0.8215\n",
      "Epoch 491/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6875 - loss: 0.841 ━━━━━━━━━━━━━━━━━━━━ 0s 59ms/step - accuracy: 0.6938 - loss: 0.8278\n",
      "Epoch 492/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.7188 - loss: 0.830 ━━━━━━━━━━━━━━━━━━━━ 0s 49ms/step - accuracy: 0.7244 - loss: 0.8172\n",
      "Epoch 493/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 40ms/step - accuracy: 0.7188 - loss: 0.806 ━━━━━━━━━━━━━━━━━━━━ 0s 67ms/step - accuracy: 0.7244 - loss: 0.8047\n",
      "Epoch 494/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step - accuracy: 0.7188 - loss: 0.822 ━━━━━━━━━━━━━━━━━━━━ 0s 77ms/step - accuracy: 0.7244 - loss: 0.8089\n",
      "Epoch 495/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 60ms/step - accuracy: 0.7188 - loss: 0.812 ━━━━━━━━━━━━━━━━━━━━ 0s 100ms/step - accuracy: 0.7244 - loss: 0.8094\n",
      "Epoch 496/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 54ms/step - accuracy: 0.6875 - loss: 0.839 ━━━━━━━━━━━━━━━━━━━━ 0s 56ms/step - accuracy: 0.6938 - loss: 0.8272\n",
      "Epoch 497/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.7188 - loss: 0.800 ━━━━━━━━━━━━━━━━━━━━ 0s 50ms/step - accuracy: 0.7042 - loss: 0.8196\n",
      "Epoch 498/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 57ms/step - accuracy: 0.7188 - loss: 0.791 ━━━━━━━━━━━━━━━━━━━━ 0s 65ms/step - accuracy: 0.7042 - loss: 0.8071\n",
      "Epoch 499/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 55ms/step - accuracy: 0.7500 - loss: 0.793 ━━━━━━━━━━━━━━━━━━━━ 0s 69ms/step - accuracy: 0.7348 - loss: 0.8007\n",
      "Epoch 500/500\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 68ms/step - accuracy: 0.6875 - loss: 0.814 ━━━━━━━━━━━━━━━━━━━━ 0s 53ms/step - accuracy: 0.6938 - loss: 0.8134\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "epochs = 500\n",
    "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "213939e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# to save the trained model\n",
    "model.save(\"chat_model.h5\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# to save the fitted tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# to save the fitted label encoder\n",
    "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
    "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2dcfbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start messaging with the bot (type quit to stop)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 161ms/st ━━━━━━━━━━━━━━━━━━━━ 0s 244ms/step\n",
      "ChatBot: Hello\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " which course is better\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 41ms/ste ━━━━━━━━━━━━━━━━━━━━ 0s 103ms/step\n",
      "ChatBot: Hi\n",
      "User: "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import colorama \n",
    "colorama.init()\n",
    "from colorama import Fore, Style, Back\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "with open(\"intents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    # load trained model\n",
    "    model = keras.models.load_model('chat_model.h5')\n",
    "\n",
    "    # load tokenizer object\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # load label encoder object\n",
    "    with open('label_encoder.pickle', 'rb') as enc:\n",
    "        lbl_encoder = pickle.load(enc)\n",
    "\n",
    "    # parameters\n",
    "    max_len = 20\n",
    "    \n",
    "    while True:\n",
    "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
    "        inp = input()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
    "                                             truncating='post', maxlen=max_len))\n",
    "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
    "\n",
    "        for i in data['intents']:\n",
    "            if i['tag'] == tag:\n",
    "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
    "\n",
    "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
    "\n",
    "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85f6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d43db49",
   "metadata": {},
   "source": [
    "# chatbot-8 GUI based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35029fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('chatbot_model.h5')\n",
    "import json\n",
    "import random\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res\n",
    "\n",
    "\n",
    "#Creating GUI with tkinter\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "\n",
    "\n",
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "\n",
    "    if msg != '':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font=(\"Verdana\", 12 ))\n",
    "    \n",
    "        res = chatbot_response(msg)\n",
    "        ChatLog.insert(END, \"iPEC: \" + res + '\\n\\n')\n",
    "            \n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    " \n",
    "\n",
    "base = Tk()\n",
    "base.title(\"Hello\")\n",
    "base.geometry(\"400x500\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "#Create Chat window\n",
    "ChatLog = Text(base, bd=0, bg=\"white\", height=\"8\", width=\"50\", font=\"Arial\",)\n",
    "\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "#Bind scrollbar to Chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor=\"heart\")\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "#Create Button to send message\n",
    "SendButton = Button(base, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#32de97\", activebackground=\"#3c9d9b\",fg='#ffffff',\n",
    "                    command= send )\n",
    "\n",
    "#Create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "#EntryBox.bind(\"<Return>\", send)\n",
    "\n",
    "\n",
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatLog.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)\n",
    "\n",
    "base.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7637112-7e6d-4ae0-9358-78f23eb23e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
